{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "import nevergrad as ng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Pressure','Temprerature','Speed','ProductionYield'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "df['Pressure'] = np.random.randint(10, high=20, size=1000)\n",
    "df['Temprerature'] = np.random.uniform(low=20, high=32, size=1000)\n",
    "df['Speed'] = np.random.uniform(low=2, high=10, size=1000)\n",
    "df['ProductionYield'] = np.sqrt(df['Pressure'])/(df['Temprerature']**2) * np.sin(df['Speed']) *1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Temprerature</th>\n",
       "      <th>Speed</th>\n",
       "      <th>ProductionYield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>24.348218</td>\n",
       "      <td>9.044236</td>\n",
       "      <td>2.170333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>29.608704</td>\n",
       "      <td>5.050024</td>\n",
       "      <td>-4.305086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>20.831865</td>\n",
       "      <td>8.046880</td>\n",
       "      <td>9.858023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>24.303317</td>\n",
       "      <td>2.111851</td>\n",
       "      <td>6.157012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>29.279170</td>\n",
       "      <td>5.172816</td>\n",
       "      <td>-4.555130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pressure  Temprerature     Speed  ProductionYield\n",
       "0        12     24.348218  9.044236         2.170333\n",
       "1        16     29.608704  5.050024        -4.305086\n",
       "2        19     20.831865  8.046880         9.858023\n",
       "3        18     24.303317  2.111851         6.157012\n",
       "4        19     29.279170  5.172816        -4.555130"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df[['Pressure','Temprerature','Speed']].values, df['ProductionYield'].values, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    # create model\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(48, input_dim=3, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(layers.Dense(128, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(layers.Dense(128, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(layers.Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.ylim([0, 15])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [MPG]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 48)                192       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               6272      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 23,105\n",
      "Trainable params: 23,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "17/17 - 0s - loss: 16.0438 - val_loss: 15.1765\n",
      "Epoch 2/600\n",
      "17/17 - 0s - loss: 15.9320 - val_loss: 15.0469\n",
      "Epoch 3/600\n",
      "17/17 - 0s - loss: 15.8449 - val_loss: 15.1300\n",
      "Epoch 4/600\n",
      "17/17 - 0s - loss: 15.7221 - val_loss: 14.6399\n",
      "Epoch 5/600\n",
      "17/17 - 0s - loss: 15.2407 - val_loss: 14.0175\n",
      "Epoch 6/600\n",
      "17/17 - 0s - loss: 15.5685 - val_loss: 14.4006\n",
      "Epoch 7/600\n",
      "17/17 - 0s - loss: 14.5133 - val_loss: 13.2298\n",
      "Epoch 8/600\n",
      "17/17 - 0s - loss: 13.8007 - val_loss: 12.6424\n",
      "Epoch 9/600\n",
      "17/17 - 0s - loss: 13.5986 - val_loss: 13.8149\n",
      "Epoch 10/600\n",
      "17/17 - 0s - loss: 13.4091 - val_loss: 12.6616\n",
      "Epoch 11/600\n",
      "17/17 - 0s - loss: 12.7985 - val_loss: 11.6980\n",
      "Epoch 12/600\n",
      "17/17 - 0s - loss: 12.3463 - val_loss: 11.7772\n",
      "Epoch 13/600\n",
      "17/17 - 0s - loss: 11.7813 - val_loss: 10.8183\n",
      "Epoch 14/600\n",
      "17/17 - 0s - loss: 10.9094 - val_loss: 9.9779\n",
      "Epoch 15/600\n",
      "17/17 - 0s - loss: 10.4935 - val_loss: 9.4431\n",
      "Epoch 16/600\n",
      "17/17 - 0s - loss: 9.6196 - val_loss: 7.6236\n",
      "Epoch 17/600\n",
      "17/17 - 0s - loss: 8.6299 - val_loss: 6.9640\n",
      "Epoch 18/600\n",
      "17/17 - 0s - loss: 7.5288 - val_loss: 7.4151\n",
      "Epoch 19/600\n",
      "17/17 - 0s - loss: 7.2717 - val_loss: 6.5938\n",
      "Epoch 20/600\n",
      "17/17 - 0s - loss: 7.6646 - val_loss: 6.7220\n",
      "Epoch 21/600\n",
      "17/17 - 0s - loss: 7.0298 - val_loss: 6.9382\n",
      "Epoch 22/600\n",
      "17/17 - 0s - loss: 6.7572 - val_loss: 6.1627\n",
      "Epoch 23/600\n",
      "17/17 - 0s - loss: 6.6514 - val_loss: 5.9052\n",
      "Epoch 24/600\n",
      "17/17 - 0s - loss: 6.2944 - val_loss: 5.7233\n",
      "Epoch 25/600\n",
      "17/17 - 0s - loss: 6.2495 - val_loss: 5.5542\n",
      "Epoch 26/600\n",
      "17/17 - 0s - loss: 6.2808 - val_loss: 6.3119\n",
      "Epoch 27/600\n",
      "17/17 - 0s - loss: 5.9931 - val_loss: 5.6797\n",
      "Epoch 28/600\n",
      "17/17 - 0s - loss: 6.0112 - val_loss: 5.6729\n",
      "Epoch 29/600\n",
      "17/17 - 0s - loss: 6.1215 - val_loss: 5.8178\n",
      "Epoch 30/600\n",
      "17/17 - 0s - loss: 5.8231 - val_loss: 5.7379\n",
      "Epoch 31/600\n",
      "17/17 - 0s - loss: 5.7780 - val_loss: 5.6844\n",
      "Epoch 32/600\n",
      "17/17 - 0s - loss: 5.8151 - val_loss: 5.6667\n",
      "Epoch 33/600\n",
      "17/17 - 0s - loss: 5.4157 - val_loss: 5.1636\n",
      "Epoch 34/600\n",
      "17/17 - 0s - loss: 5.2646 - val_loss: 5.8465\n",
      "Epoch 35/600\n",
      "17/17 - 0s - loss: 5.4170 - val_loss: 5.2995\n",
      "Epoch 36/600\n",
      "17/17 - 0s - loss: 4.9951 - val_loss: 4.7384\n",
      "Epoch 37/600\n",
      "17/17 - 0s - loss: 5.1249 - val_loss: 5.3254\n",
      "Epoch 38/600\n",
      "17/17 - 0s - loss: 4.8274 - val_loss: 4.5095\n",
      "Epoch 39/600\n",
      "17/17 - 0s - loss: 5.3875 - val_loss: 5.4079\n",
      "Epoch 40/600\n",
      "17/17 - 0s - loss: 5.3501 - val_loss: 4.5530\n",
      "Epoch 41/600\n",
      "17/17 - 0s - loss: 5.0858 - val_loss: 4.8354\n",
      "Epoch 42/600\n",
      "17/17 - 0s - loss: 4.4192 - val_loss: 4.2450\n",
      "Epoch 43/600\n",
      "17/17 - 0s - loss: 4.4058 - val_loss: 4.6297\n",
      "Epoch 44/600\n",
      "17/17 - 0s - loss: 4.1963 - val_loss: 4.6555\n",
      "Epoch 45/600\n",
      "17/17 - 0s - loss: 4.5948 - val_loss: 5.0706\n",
      "Epoch 46/600\n",
      "17/17 - 0s - loss: 4.0026 - val_loss: 3.8926\n",
      "Epoch 47/600\n",
      "17/17 - 0s - loss: 4.4464 - val_loss: 4.0902\n",
      "Epoch 48/600\n",
      "17/17 - 0s - loss: 4.3134 - val_loss: 4.1826\n",
      "Epoch 49/600\n",
      "17/17 - 0s - loss: 4.3045 - val_loss: 4.0940\n",
      "Epoch 50/600\n",
      "17/17 - 0s - loss: 3.5763 - val_loss: 3.5486\n",
      "Epoch 51/600\n",
      "17/17 - 0s - loss: 3.6596 - val_loss: 3.6531\n",
      "Epoch 52/600\n",
      "17/17 - 0s - loss: 3.6216 - val_loss: 4.3577\n",
      "Epoch 53/600\n",
      "17/17 - 0s - loss: 3.2660 - val_loss: 3.4529\n",
      "Epoch 54/600\n",
      "17/17 - 0s - loss: 3.5061 - val_loss: 3.4204\n",
      "Epoch 55/600\n",
      "17/17 - 0s - loss: 3.2285 - val_loss: 3.3604\n",
      "Epoch 56/600\n",
      "17/17 - 0s - loss: 2.9432 - val_loss: 3.5290\n",
      "Epoch 57/600\n",
      "17/17 - 0s - loss: 2.8643 - val_loss: 3.2941\n",
      "Epoch 58/600\n",
      "17/17 - 0s - loss: 2.9193 - val_loss: 3.0406\n",
      "Epoch 59/600\n",
      "17/17 - 0s - loss: 2.7154 - val_loss: 2.8897\n",
      "Epoch 60/600\n",
      "17/17 - 0s - loss: 2.6186 - val_loss: 3.2219\n",
      "Epoch 61/600\n",
      "17/17 - 0s - loss: 2.4830 - val_loss: 2.6017\n",
      "Epoch 62/600\n",
      "17/17 - 0s - loss: 2.3088 - val_loss: 2.7106\n",
      "Epoch 63/600\n",
      "17/17 - 0s - loss: 2.2284 - val_loss: 3.0383\n",
      "Epoch 64/600\n",
      "17/17 - 0s - loss: 2.2848 - val_loss: 2.7327\n",
      "Epoch 65/600\n",
      "17/17 - 0s - loss: 2.0556 - val_loss: 2.5074\n",
      "Epoch 66/600\n",
      "17/17 - 0s - loss: 1.9513 - val_loss: 2.1843\n",
      "Epoch 67/600\n",
      "17/17 - 0s - loss: 1.8629 - val_loss: 2.3412\n",
      "Epoch 68/600\n",
      "17/17 - 0s - loss: 2.0624 - val_loss: 2.2772\n",
      "Epoch 69/600\n",
      "17/17 - 0s - loss: 1.8986 - val_loss: 2.1672\n",
      "Epoch 70/600\n",
      "17/17 - 0s - loss: 1.7744 - val_loss: 2.4006\n",
      "Epoch 71/600\n",
      "17/17 - 0s - loss: 1.5463 - val_loss: 2.1088\n",
      "Epoch 72/600\n",
      "17/17 - 0s - loss: 1.4496 - val_loss: 1.8199\n",
      "Epoch 73/600\n",
      "17/17 - 0s - loss: 1.4150 - val_loss: 1.8146\n",
      "Epoch 74/600\n",
      "17/17 - 0s - loss: 1.4871 - val_loss: 1.7109\n",
      "Epoch 75/600\n",
      "17/17 - 0s - loss: 1.2802 - val_loss: 1.7384\n",
      "Epoch 76/600\n",
      "17/17 - 0s - loss: 1.3412 - val_loss: 2.8850\n",
      "Epoch 77/600\n",
      "17/17 - 0s - loss: 1.7252 - val_loss: 1.7551\n",
      "Epoch 78/600\n",
      "17/17 - 0s - loss: 1.1620 - val_loss: 1.7644\n",
      "Epoch 79/600\n",
      "17/17 - 0s - loss: 1.2817 - val_loss: 1.3630\n",
      "Epoch 80/600\n",
      "17/17 - 0s - loss: 1.0442 - val_loss: 1.4609\n",
      "Epoch 81/600\n",
      "17/17 - 0s - loss: 1.0642 - val_loss: 1.2832\n",
      "Epoch 82/600\n",
      "17/17 - 0s - loss: 0.9990 - val_loss: 1.3031\n",
      "Epoch 83/600\n",
      "17/17 - 0s - loss: 0.8853 - val_loss: 1.2104\n",
      "Epoch 84/600\n",
      "17/17 - 0s - loss: 0.7908 - val_loss: 1.5765\n",
      "Epoch 85/600\n",
      "17/17 - 0s - loss: 0.8551 - val_loss: 1.0287\n",
      "Epoch 86/600\n",
      "17/17 - 0s - loss: 1.0415 - val_loss: 1.8387\n",
      "Epoch 87/600\n",
      "17/17 - 0s - loss: 1.0816 - val_loss: 1.2471\n",
      "Epoch 88/600\n",
      "17/17 - 0s - loss: 0.8777 - val_loss: 0.9188\n",
      "Epoch 89/600\n",
      "17/17 - 0s - loss: 0.6421 - val_loss: 0.9750\n",
      "Epoch 90/600\n",
      "17/17 - 0s - loss: 0.5056 - val_loss: 0.7471\n",
      "Epoch 91/600\n",
      "17/17 - 0s - loss: 0.4876 - val_loss: 0.7282\n",
      "Epoch 92/600\n",
      "17/17 - 0s - loss: 0.4509 - val_loss: 0.6704\n",
      "Epoch 93/600\n",
      "17/17 - 0s - loss: 0.5009 - val_loss: 0.9594\n",
      "Epoch 94/600\n",
      "17/17 - 0s - loss: 0.5468 - val_loss: 0.6302\n",
      "Epoch 95/600\n",
      "17/17 - 0s - loss: 0.3839 - val_loss: 0.5976\n",
      "Epoch 96/600\n",
      "17/17 - 0s - loss: 0.3084 - val_loss: 0.6381\n",
      "Epoch 97/600\n",
      "17/17 - 0s - loss: 0.3043 - val_loss: 0.5715\n",
      "Epoch 98/600\n",
      "17/17 - 0s - loss: 0.2762 - val_loss: 0.4518\n",
      "Epoch 99/600\n",
      "17/17 - 0s - loss: 0.3827 - val_loss: 0.4303\n",
      "Epoch 100/600\n",
      "17/17 - 0s - loss: 0.2751 - val_loss: 0.5671\n",
      "Epoch 101/600\n",
      "17/17 - 0s - loss: 0.2623 - val_loss: 0.5455\n",
      "Epoch 102/600\n",
      "17/17 - 0s - loss: 0.3308 - val_loss: 0.3877\n",
      "Epoch 103/600\n",
      "17/17 - 0s - loss: 0.3281 - val_loss: 0.4050\n",
      "Epoch 104/600\n",
      "17/17 - 0s - loss: 0.2862 - val_loss: 0.5374\n",
      "Epoch 105/600\n",
      "17/17 - 0s - loss: 0.2697 - val_loss: 0.4282\n",
      "Epoch 106/600\n",
      "17/17 - 0s - loss: 0.1934 - val_loss: 0.4314\n",
      "Epoch 107/600\n",
      "17/17 - 0s - loss: 0.1812 - val_loss: 0.5317\n",
      "Epoch 108/600\n",
      "17/17 - 0s - loss: 0.3129 - val_loss: 0.7744\n",
      "Epoch 109/600\n",
      "17/17 - 0s - loss: 0.2505 - val_loss: 0.2967\n",
      "Epoch 110/600\n",
      "17/17 - 0s - loss: 0.2171 - val_loss: 0.3069\n",
      "Epoch 111/600\n",
      "17/17 - 0s - loss: 0.1980 - val_loss: 0.4271\n",
      "Epoch 112/600\n",
      "17/17 - 0s - loss: 0.1626 - val_loss: 0.3985\n",
      "Epoch 113/600\n",
      "17/17 - 0s - loss: 0.1628 - val_loss: 0.4567\n",
      "Epoch 114/600\n",
      "17/17 - 0s - loss: 0.1979 - val_loss: 0.4217\n",
      "Epoch 115/600\n",
      "17/17 - 0s - loss: 0.1908 - val_loss: 0.3125\n",
      "Epoch 116/600\n",
      "17/17 - 0s - loss: 0.2358 - val_loss: 0.3154\n",
      "Epoch 117/600\n",
      "17/17 - 0s - loss: 0.1601 - val_loss: 0.2726\n",
      "Epoch 118/600\n",
      "17/17 - 0s - loss: 0.1823 - val_loss: 0.2996\n",
      "Epoch 119/600\n",
      "17/17 - 0s - loss: 0.2259 - val_loss: 0.2677\n",
      "Epoch 120/600\n",
      "17/17 - 0s - loss: 0.1496 - val_loss: 0.2564\n",
      "Epoch 121/600\n",
      "17/17 - 0s - loss: 0.1520 - val_loss: 0.3533\n",
      "Epoch 122/600\n",
      "17/17 - 0s - loss: 0.1179 - val_loss: 0.2480\n",
      "Epoch 123/600\n",
      "17/17 - 0s - loss: 0.1019 - val_loss: 0.2047\n",
      "Epoch 124/600\n",
      "17/17 - 0s - loss: 0.1343 - val_loss: 0.2603\n",
      "Epoch 125/600\n",
      "17/17 - 0s - loss: 0.1221 - val_loss: 0.2207\n",
      "Epoch 126/600\n",
      "17/17 - 0s - loss: 0.1051 - val_loss: 0.2442\n",
      "Epoch 127/600\n",
      "17/17 - 0s - loss: 0.1713 - val_loss: 0.2279\n",
      "Epoch 128/600\n",
      "17/17 - 0s - loss: 0.1649 - val_loss: 0.3429\n",
      "Epoch 129/600\n",
      "17/17 - 0s - loss: 0.1949 - val_loss: 0.7594\n",
      "Epoch 130/600\n",
      "17/17 - 0s - loss: 0.3959 - val_loss: 0.5862\n",
      "Epoch 131/600\n",
      "17/17 - 0s - loss: 0.2270 - val_loss: 0.5738\n",
      "Epoch 132/600\n",
      "17/17 - 0s - loss: 0.1326 - val_loss: 0.3697\n",
      "Epoch 133/600\n",
      "17/17 - 0s - loss: 0.0964 - val_loss: 0.1992\n",
      "Epoch 134/600\n",
      "17/17 - 0s - loss: 0.0989 - val_loss: 0.2119\n",
      "Epoch 135/600\n",
      "17/17 - 0s - loss: 0.0791 - val_loss: 0.2001\n",
      "Epoch 136/600\n",
      "17/17 - 0s - loss: 0.1016 - val_loss: 0.3372\n",
      "Epoch 137/600\n",
      "17/17 - 0s - loss: 0.1158 - val_loss: 0.2502\n",
      "Epoch 138/600\n",
      "17/17 - 0s - loss: 0.1338 - val_loss: 0.2002\n",
      "Epoch 139/600\n",
      "17/17 - 0s - loss: 0.0936 - val_loss: 0.1795\n",
      "Epoch 140/600\n",
      "17/17 - 0s - loss: 0.0789 - val_loss: 0.1688\n",
      "Epoch 141/600\n",
      "17/17 - 0s - loss: 0.1117 - val_loss: 0.1963\n",
      "Epoch 142/600\n",
      "17/17 - 0s - loss: 0.1777 - val_loss: 0.1801\n",
      "Epoch 143/600\n",
      "17/17 - 0s - loss: 0.1113 - val_loss: 0.1777\n",
      "Epoch 144/600\n",
      "17/17 - 0s - loss: 0.1105 - val_loss: 0.1800\n",
      "Epoch 145/600\n",
      "17/17 - 0s - loss: 0.0851 - val_loss: 0.1516\n",
      "Epoch 146/600\n",
      "17/17 - 0s - loss: 0.1014 - val_loss: 0.1793\n",
      "Epoch 147/600\n",
      "17/17 - 0s - loss: 0.0740 - val_loss: 0.1562\n",
      "Epoch 148/600\n",
      "17/17 - 0s - loss: 0.1015 - val_loss: 0.1753\n",
      "Epoch 149/600\n",
      "17/17 - 0s - loss: 0.1184 - val_loss: 0.2079\n",
      "Epoch 150/600\n",
      "17/17 - 0s - loss: 0.1306 - val_loss: 0.5409\n",
      "Epoch 151/600\n",
      "17/17 - 0s - loss: 0.2240 - val_loss: 0.4173\n",
      "Epoch 152/600\n",
      "17/17 - 0s - loss: 0.1916 - val_loss: 0.2497\n",
      "Epoch 153/600\n",
      "17/17 - 0s - loss: 0.1412 - val_loss: 0.1646\n",
      "Epoch 154/600\n",
      "17/17 - 0s - loss: 0.1294 - val_loss: 0.2584\n",
      "Epoch 155/600\n",
      "17/17 - 0s - loss: 0.3255 - val_loss: 0.1968\n",
      "Epoch 156/600\n",
      "17/17 - 0s - loss: 0.3159 - val_loss: 0.1959\n",
      "Epoch 157/600\n",
      "17/17 - 0s - loss: 0.1845 - val_loss: 0.1686\n",
      "Epoch 158/600\n",
      "17/17 - 0s - loss: 0.0973 - val_loss: 0.1972\n",
      "Epoch 159/600\n",
      "17/17 - 0s - loss: 0.1487 - val_loss: 0.1769\n",
      "Epoch 160/600\n",
      "17/17 - 0s - loss: 0.1147 - val_loss: 0.2486\n",
      "Epoch 161/600\n",
      "17/17 - 0s - loss: 0.2062 - val_loss: 0.2116\n",
      "Epoch 162/600\n",
      "17/17 - 0s - loss: 0.1239 - val_loss: 0.1398\n",
      "Epoch 163/600\n",
      "17/17 - 0s - loss: 0.0872 - val_loss: 0.1445\n",
      "Epoch 164/600\n",
      "17/17 - 0s - loss: 0.0696 - val_loss: 0.1389\n",
      "Epoch 165/600\n",
      "17/17 - 0s - loss: 0.1174 - val_loss: 0.1285\n",
      "Epoch 166/600\n",
      "17/17 - 0s - loss: 0.1122 - val_loss: 0.4031\n",
      "Epoch 167/600\n",
      "17/17 - 0s - loss: 0.1822 - val_loss: 0.1292\n",
      "Epoch 168/600\n",
      "17/17 - 0s - loss: 0.1630 - val_loss: 0.1800\n",
      "Epoch 169/600\n",
      "17/17 - 0s - loss: 0.0930 - val_loss: 0.1379\n",
      "Epoch 170/600\n",
      "17/17 - 0s - loss: 0.0699 - val_loss: 0.1418\n",
      "Epoch 171/600\n",
      "17/17 - 0s - loss: 0.0620 - val_loss: 0.1055\n",
      "Epoch 172/600\n",
      "17/17 - 0s - loss: 0.1638 - val_loss: 0.3115\n",
      "Epoch 173/600\n",
      "17/17 - 0s - loss: 0.0847 - val_loss: 0.1669\n",
      "Epoch 174/600\n",
      "17/17 - 0s - loss: 0.0451 - val_loss: 0.1219\n",
      "Epoch 175/600\n",
      "17/17 - 0s - loss: 0.0487 - val_loss: 0.1358\n",
      "Epoch 176/600\n",
      "17/17 - 0s - loss: 0.0866 - val_loss: 0.1646\n",
      "Epoch 177/600\n",
      "17/17 - 0s - loss: 0.0880 - val_loss: 0.1037\n",
      "Epoch 178/600\n",
      "17/17 - 0s - loss: 0.0686 - val_loss: 0.1094\n",
      "Epoch 179/600\n",
      "17/17 - 0s - loss: 0.0615 - val_loss: 0.1504\n",
      "Epoch 180/600\n",
      "17/17 - 0s - loss: 0.0883 - val_loss: 0.1588\n",
      "Epoch 181/600\n",
      "17/17 - 0s - loss: 0.0942 - val_loss: 0.0921\n",
      "Epoch 182/600\n",
      "17/17 - 0s - loss: 0.0753 - val_loss: 0.1168\n",
      "Epoch 183/600\n",
      "17/17 - 0s - loss: 0.0622 - val_loss: 0.1363\n",
      "Epoch 184/600\n",
      "17/17 - 0s - loss: 0.0483 - val_loss: 0.1004\n",
      "Epoch 185/600\n",
      "17/17 - 0s - loss: 0.0529 - val_loss: 0.0995\n",
      "Epoch 186/600\n",
      "17/17 - 0s - loss: 0.0553 - val_loss: 0.1087\n",
      "Epoch 187/600\n",
      "17/17 - 0s - loss: 0.0710 - val_loss: 0.0941\n",
      "Epoch 188/600\n",
      "17/17 - 0s - loss: 0.0442 - val_loss: 0.1317\n",
      "Epoch 189/600\n",
      "17/17 - 0s - loss: 0.0514 - val_loss: 0.0938\n",
      "Epoch 190/600\n",
      "17/17 - 0s - loss: 0.0610 - val_loss: 0.1166\n",
      "Epoch 191/600\n",
      "17/17 - 0s - loss: 0.0411 - val_loss: 0.1887\n",
      "Epoch 192/600\n",
      "17/17 - 0s - loss: 0.0550 - val_loss: 0.1447\n",
      "Epoch 193/600\n",
      "17/17 - 0s - loss: 0.0653 - val_loss: 0.1607\n",
      "Epoch 194/600\n",
      "17/17 - 0s - loss: 0.0564 - val_loss: 0.0812\n",
      "Epoch 195/600\n",
      "17/17 - 0s - loss: 0.1201 - val_loss: 0.1225\n",
      "Epoch 196/600\n",
      "17/17 - 0s - loss: 0.1417 - val_loss: 0.1631\n",
      "Epoch 197/600\n",
      "17/17 - 0s - loss: 0.0888 - val_loss: 0.1041\n",
      "Epoch 198/600\n",
      "17/17 - 0s - loss: 0.0802 - val_loss: 0.1257\n",
      "Epoch 199/600\n",
      "17/17 - 0s - loss: 0.1138 - val_loss: 0.1992\n",
      "Epoch 200/600\n",
      "17/17 - 0s - loss: 0.0749 - val_loss: 0.1111\n",
      "Epoch 201/600\n",
      "17/17 - 0s - loss: 0.0937 - val_loss: 0.0996\n",
      "Epoch 202/600\n",
      "17/17 - 0s - loss: 0.0725 - val_loss: 0.0876\n",
      "Epoch 203/600\n",
      "17/17 - 0s - loss: 0.0598 - val_loss: 0.1171\n",
      "Epoch 204/600\n",
      "17/17 - 0s - loss: 0.0352 - val_loss: 0.0805\n",
      "Epoch 205/600\n",
      "17/17 - 0s - loss: 0.0510 - val_loss: 0.1442\n",
      "Epoch 206/600\n",
      "17/17 - 0s - loss: 0.0581 - val_loss: 0.1066\n",
      "Epoch 207/600\n",
      "17/17 - 0s - loss: 0.1717 - val_loss: 0.1619\n",
      "Epoch 208/600\n",
      "17/17 - 0s - loss: 0.1649 - val_loss: 0.1335\n",
      "Epoch 209/600\n",
      "17/17 - 0s - loss: 0.0567 - val_loss: 0.1001\n",
      "Epoch 210/600\n",
      "17/17 - 0s - loss: 0.0399 - val_loss: 0.0719\n",
      "Epoch 211/600\n",
      "17/17 - 0s - loss: 0.0329 - val_loss: 0.0833\n",
      "Epoch 212/600\n",
      "17/17 - 0s - loss: 0.0505 - val_loss: 0.1320\n",
      "Epoch 213/600\n",
      "17/17 - 0s - loss: 0.0612 - val_loss: 0.1967\n",
      "Epoch 214/600\n",
      "17/17 - 0s - loss: 0.2197 - val_loss: 0.1752\n",
      "Epoch 215/600\n",
      "17/17 - 0s - loss: 1.0429 - val_loss: 1.3979\n",
      "Epoch 216/600\n",
      "17/17 - 0s - loss: 0.5616 - val_loss: 0.3915\n",
      "Epoch 217/600\n",
      "17/17 - 0s - loss: 0.2226 - val_loss: 0.1886\n",
      "Epoch 218/600\n",
      "17/17 - 0s - loss: 0.2053 - val_loss: 0.4033\n",
      "Epoch 219/600\n",
      "17/17 - 0s - loss: 0.1112 - val_loss: 0.1651\n",
      "Epoch 220/600\n",
      "17/17 - 0s - loss: 0.1112 - val_loss: 0.1588\n",
      "Epoch 221/600\n",
      "17/17 - 0s - loss: 0.0390 - val_loss: 0.0855\n",
      "Epoch 222/600\n",
      "17/17 - 0s - loss: 0.0324 - val_loss: 0.0846\n",
      "Epoch 223/600\n",
      "17/17 - 0s - loss: 0.0408 - val_loss: 0.0724\n",
      "Epoch 224/600\n",
      "17/17 - 0s - loss: 0.0278 - val_loss: 0.0675\n",
      "Epoch 225/600\n",
      "17/17 - 0s - loss: 0.0362 - val_loss: 0.0796\n",
      "Epoch 226/600\n",
      "17/17 - 0s - loss: 0.0312 - val_loss: 0.0618\n",
      "Epoch 227/600\n",
      "17/17 - 0s - loss: 0.0345 - val_loss: 0.0713\n",
      "Epoch 228/600\n",
      "17/17 - 0s - loss: 0.0551 - val_loss: 0.1038\n",
      "Epoch 229/600\n",
      "17/17 - 0s - loss: 0.0672 - val_loss: 0.1815\n",
      "Epoch 230/600\n",
      "17/17 - 0s - loss: 0.0457 - val_loss: 0.0921\n",
      "Epoch 231/600\n",
      "17/17 - 0s - loss: 0.0352 - val_loss: 0.0738\n",
      "Epoch 232/600\n",
      "17/17 - 0s - loss: 0.0639 - val_loss: 0.1002\n",
      "Epoch 233/600\n",
      "17/17 - 0s - loss: 0.0721 - val_loss: 0.0918\n",
      "Epoch 234/600\n",
      "17/17 - 0s - loss: 0.0630 - val_loss: 0.1017\n",
      "Epoch 235/600\n",
      "17/17 - 0s - loss: 0.0482 - val_loss: 0.0668\n",
      "Epoch 236/600\n",
      "17/17 - 0s - loss: 0.0350 - val_loss: 0.1130\n",
      "Epoch 237/600\n",
      "17/17 - 0s - loss: 0.0551 - val_loss: 0.0812\n",
      "Epoch 238/600\n",
      "17/17 - 0s - loss: 0.0448 - val_loss: 0.1082\n",
      "Epoch 239/600\n",
      "17/17 - 0s - loss: 0.0350 - val_loss: 0.0803\n",
      "Epoch 240/600\n",
      "17/17 - 0s - loss: 0.0269 - val_loss: 0.0522\n",
      "Epoch 241/600\n",
      "17/17 - 0s - loss: 0.0472 - val_loss: 0.0752\n",
      "Epoch 242/600\n",
      "17/17 - 0s - loss: 0.0410 - val_loss: 0.1154\n",
      "Epoch 243/600\n",
      "17/17 - 0s - loss: 0.0522 - val_loss: 0.1044\n",
      "Epoch 244/600\n",
      "17/17 - 0s - loss: 0.0682 - val_loss: 0.0589\n",
      "Epoch 245/600\n",
      "17/17 - 0s - loss: 0.0366 - val_loss: 0.1984\n",
      "Epoch 246/600\n",
      "17/17 - 0s - loss: 0.0703 - val_loss: 0.0678\n",
      "Epoch 247/600\n",
      "17/17 - 0s - loss: 0.0369 - val_loss: 0.0692\n",
      "Epoch 248/600\n",
      "17/17 - 0s - loss: 0.0251 - val_loss: 0.0468\n",
      "Epoch 249/600\n",
      "17/17 - 0s - loss: 0.0247 - val_loss: 0.0778\n",
      "Epoch 250/600\n",
      "17/17 - 0s - loss: 0.0292 - val_loss: 0.0666\n",
      "Epoch 251/600\n",
      "17/17 - 0s - loss: 0.0254 - val_loss: 0.0657\n",
      "Epoch 252/600\n",
      "17/17 - 0s - loss: 0.0351 - val_loss: 0.0889\n",
      "Epoch 253/600\n",
      "17/17 - 0s - loss: 0.0226 - val_loss: 0.0419\n",
      "Epoch 254/600\n",
      "17/17 - 0s - loss: 0.0251 - val_loss: 0.0647\n",
      "Epoch 255/600\n",
      "17/17 - 0s - loss: 0.0242 - val_loss: 0.0480\n",
      "Epoch 256/600\n",
      "17/17 - 0s - loss: 0.0281 - val_loss: 0.0662\n",
      "Epoch 257/600\n",
      "17/17 - 0s - loss: 0.0203 - val_loss: 0.0514\n",
      "Epoch 258/600\n",
      "17/17 - 0s - loss: 0.0333 - val_loss: 0.0798\n",
      "Epoch 259/600\n",
      "17/17 - 0s - loss: 0.0257 - val_loss: 0.0468\n",
      "Epoch 260/600\n",
      "17/17 - 0s - loss: 0.0458 - val_loss: 0.0568\n",
      "Epoch 261/600\n",
      "17/17 - 0s - loss: 0.0754 - val_loss: 0.0807\n",
      "Epoch 262/600\n",
      "17/17 - 0s - loss: 0.0331 - val_loss: 0.0547\n",
      "Epoch 263/600\n",
      "17/17 - 0s - loss: 0.0308 - val_loss: 0.0543\n",
      "Epoch 264/600\n",
      "17/17 - 0s - loss: 0.0216 - val_loss: 0.0619\n",
      "Epoch 265/600\n",
      "17/17 - 0s - loss: 0.0416 - val_loss: 0.0484\n",
      "Epoch 266/600\n",
      "17/17 - 0s - loss: 0.0314 - val_loss: 0.0636\n",
      "Epoch 267/600\n",
      "17/17 - 0s - loss: 0.0526 - val_loss: 0.0922\n",
      "Epoch 268/600\n",
      "17/17 - 0s - loss: 0.0381 - val_loss: 0.0534\n",
      "Epoch 269/600\n",
      "17/17 - 0s - loss: 0.0479 - val_loss: 0.0698\n",
      "Epoch 270/600\n",
      "17/17 - 0s - loss: 0.0508 - val_loss: 0.0488\n",
      "Epoch 271/600\n",
      "17/17 - 0s - loss: 0.0326 - val_loss: 0.0486\n",
      "Epoch 272/600\n",
      "17/17 - 0s - loss: 0.0230 - val_loss: 0.0407\n",
      "Epoch 273/600\n",
      "17/17 - 0s - loss: 0.0189 - val_loss: 0.0500\n",
      "Epoch 274/600\n",
      "17/17 - 0s - loss: 0.0189 - val_loss: 0.0365\n",
      "Epoch 275/600\n",
      "17/17 - 0s - loss: 0.0191 - val_loss: 0.0450\n",
      "Epoch 276/600\n",
      "17/17 - 0s - loss: 0.0445 - val_loss: 0.1811\n",
      "Epoch 277/600\n",
      "17/17 - 0s - loss: 0.0768 - val_loss: 0.0748\n",
      "Epoch 278/600\n",
      "17/17 - 0s - loss: 0.0578 - val_loss: 0.0590\n",
      "Epoch 279/600\n",
      "17/17 - 0s - loss: 0.0644 - val_loss: 0.0411\n",
      "Epoch 280/600\n",
      "17/17 - 0s - loss: 0.0402 - val_loss: 0.0538\n",
      "Epoch 281/600\n",
      "17/17 - 0s - loss: 0.0234 - val_loss: 0.0447\n",
      "Epoch 282/600\n",
      "17/17 - 0s - loss: 0.0214 - val_loss: 0.0629\n",
      "Epoch 283/600\n",
      "17/17 - 0s - loss: 0.0388 - val_loss: 0.0803\n",
      "Epoch 284/600\n",
      "17/17 - 0s - loss: 0.0380 - val_loss: 0.0581\n",
      "Epoch 285/600\n",
      "17/17 - 0s - loss: 0.0363 - val_loss: 0.0445\n",
      "Epoch 286/600\n",
      "17/17 - 0s - loss: 0.0319 - val_loss: 0.0642\n",
      "Epoch 287/600\n",
      "17/17 - 0s - loss: 0.0805 - val_loss: 0.1755\n",
      "Epoch 288/600\n",
      "17/17 - 0s - loss: 0.1409 - val_loss: 0.1102\n",
      "Epoch 289/600\n",
      "17/17 - 0s - loss: 0.0429 - val_loss: 0.0561\n",
      "Epoch 290/600\n",
      "17/17 - 0s - loss: 0.0312 - val_loss: 0.0492\n",
      "Epoch 291/600\n",
      "17/17 - 0s - loss: 0.0271 - val_loss: 0.0706\n",
      "Epoch 292/600\n",
      "17/17 - 0s - loss: 0.0518 - val_loss: 0.0641\n",
      "Epoch 293/600\n",
      "17/17 - 0s - loss: 0.0307 - val_loss: 0.0355\n",
      "Epoch 294/600\n",
      "17/17 - 0s - loss: 0.0136 - val_loss: 0.0333\n",
      "Epoch 295/600\n",
      "17/17 - 0s - loss: 0.0176 - val_loss: 0.0353\n",
      "Epoch 296/600\n",
      "17/17 - 0s - loss: 0.0131 - val_loss: 0.0833\n",
      "Epoch 297/600\n",
      "17/17 - 0s - loss: 0.0395 - val_loss: 0.0565\n",
      "Epoch 298/600\n",
      "17/17 - 0s - loss: 0.0188 - val_loss: 0.0366\n",
      "Epoch 299/600\n",
      "17/17 - 0s - loss: 0.0149 - val_loss: 0.0376\n",
      "Epoch 300/600\n",
      "17/17 - 0s - loss: 0.0345 - val_loss: 0.0859\n",
      "Epoch 301/600\n",
      "17/17 - 0s - loss: 0.0323 - val_loss: 0.0550\n",
      "Epoch 302/600\n",
      "17/17 - 0s - loss: 0.0443 - val_loss: 0.1127\n",
      "Epoch 303/600\n",
      "17/17 - 0s - loss: 0.0469 - val_loss: 0.0622\n",
      "Epoch 304/600\n",
      "17/17 - 0s - loss: 0.0478 - val_loss: 0.0326\n",
      "Epoch 305/600\n",
      "17/17 - 0s - loss: 0.0260 - val_loss: 0.0487\n",
      "Epoch 306/600\n",
      "17/17 - 0s - loss: 0.0427 - val_loss: 0.0892\n",
      "Epoch 307/600\n",
      "17/17 - 0s - loss: 0.1128 - val_loss: 0.0932\n",
      "Epoch 308/600\n",
      "17/17 - 0s - loss: 0.0597 - val_loss: 0.1027\n",
      "Epoch 309/600\n",
      "17/17 - 0s - loss: 0.0503 - val_loss: 0.0830\n",
      "Epoch 310/600\n",
      "17/17 - 0s - loss: 0.0576 - val_loss: 0.0596\n",
      "Epoch 311/600\n",
      "17/17 - 0s - loss: 0.0441 - val_loss: 0.0349\n",
      "Epoch 312/600\n",
      "17/17 - 0s - loss: 0.0193 - val_loss: 0.0656\n",
      "Epoch 313/600\n",
      "17/17 - 0s - loss: 0.0298 - val_loss: 0.0309\n",
      "Epoch 314/600\n",
      "17/17 - 0s - loss: 0.0311 - val_loss: 0.0522\n",
      "Epoch 315/600\n",
      "17/17 - 0s - loss: 0.0343 - val_loss: 0.0522\n",
      "Epoch 316/600\n",
      "17/17 - 0s - loss: 0.0271 - val_loss: 0.0518\n",
      "Epoch 317/600\n",
      "17/17 - 0s - loss: 0.0293 - val_loss: 0.0500\n",
      "Epoch 318/600\n",
      "17/17 - 0s - loss: 0.0201 - val_loss: 0.0470\n",
      "Epoch 319/600\n",
      "17/17 - 0s - loss: 0.0244 - val_loss: 0.0718\n",
      "Epoch 320/600\n",
      "17/17 - 0s - loss: 0.0187 - val_loss: 0.0451\n",
      "Epoch 321/600\n",
      "17/17 - 0s - loss: 0.0213 - val_loss: 0.0355\n",
      "Epoch 322/600\n",
      "17/17 - 0s - loss: 0.0226 - val_loss: 0.0339\n",
      "Epoch 323/600\n",
      "17/17 - 0s - loss: 0.0290 - val_loss: 0.0430\n",
      "Epoch 324/600\n",
      "17/17 - 0s - loss: 0.0265 - val_loss: 0.0730\n",
      "Epoch 325/600\n",
      "17/17 - 0s - loss: 0.0448 - val_loss: 0.0656\n",
      "Epoch 326/600\n",
      "17/17 - 0s - loss: 0.0165 - val_loss: 0.0432\n",
      "Epoch 327/600\n",
      "17/17 - 0s - loss: 0.0175 - val_loss: 0.0331\n",
      "Epoch 328/600\n",
      "17/17 - 0s - loss: 0.0287 - val_loss: 0.0921\n",
      "Epoch 329/600\n",
      "17/17 - 0s - loss: 0.0456 - val_loss: 0.0715\n",
      "Epoch 330/600\n",
      "17/17 - 0s - loss: 0.0390 - val_loss: 0.0802\n",
      "Epoch 331/600\n",
      "17/17 - 0s - loss: 0.0729 - val_loss: 0.5985\n",
      "Epoch 332/600\n",
      "17/17 - 0s - loss: 0.2129 - val_loss: 0.2082\n",
      "Epoch 333/600\n",
      "17/17 - 0s - loss: 0.0672 - val_loss: 0.0638\n",
      "Epoch 334/600\n",
      "17/17 - 0s - loss: 0.0369 - val_loss: 0.0457\n",
      "Epoch 335/600\n",
      "17/17 - 0s - loss: 0.0405 - val_loss: 0.0374\n",
      "Epoch 336/600\n",
      "17/17 - 0s - loss: 0.0712 - val_loss: 0.1693\n",
      "Epoch 337/600\n",
      "17/17 - 0s - loss: 0.1033 - val_loss: 0.0854\n",
      "Epoch 338/600\n",
      "17/17 - 0s - loss: 0.1108 - val_loss: 0.2216\n",
      "Epoch 339/600\n",
      "17/17 - 0s - loss: 0.1858 - val_loss: 0.2233\n",
      "Epoch 340/600\n",
      "17/17 - 0s - loss: 0.0762 - val_loss: 0.0867\n",
      "Epoch 341/600\n",
      "17/17 - 0s - loss: 0.0584 - val_loss: 0.0755\n",
      "Epoch 342/600\n",
      "17/17 - 0s - loss: 0.0701 - val_loss: 0.1037\n",
      "Epoch 343/600\n",
      "17/17 - 0s - loss: 0.1419 - val_loss: 0.0785\n",
      "Epoch 344/600\n",
      "17/17 - 0s - loss: 0.0635 - val_loss: 0.1112\n",
      "Epoch 345/600\n",
      "17/17 - 0s - loss: 0.0255 - val_loss: 0.0613\n",
      "Epoch 346/600\n",
      "17/17 - 0s - loss: 0.0187 - val_loss: 0.0397\n",
      "Epoch 347/600\n",
      "17/17 - 0s - loss: 0.0211 - val_loss: 0.0419\n",
      "Epoch 348/600\n",
      "17/17 - 0s - loss: 0.0243 - val_loss: 0.0825\n",
      "Epoch 349/600\n",
      "17/17 - 0s - loss: 0.0623 - val_loss: 0.1550\n",
      "Epoch 350/600\n",
      "17/17 - 0s - loss: 0.1040 - val_loss: 0.0797\n",
      "Epoch 351/600\n",
      "17/17 - 0s - loss: 0.0870 - val_loss: 0.1372\n",
      "Epoch 352/600\n",
      "17/17 - 0s - loss: 0.1296 - val_loss: 0.1338\n",
      "Epoch 353/600\n",
      "17/17 - 0s - loss: 0.0846 - val_loss: 0.2051\n",
      "Epoch 354/600\n",
      "17/17 - 0s - loss: 0.0481 - val_loss: 0.0621\n",
      "Epoch 355/600\n",
      "17/17 - 0s - loss: 0.0392 - val_loss: 0.0689\n",
      "Epoch 356/600\n",
      "17/17 - 0s - loss: 0.0401 - val_loss: 0.0577\n",
      "Epoch 357/600\n",
      "17/17 - 0s - loss: 0.0304 - val_loss: 0.3245\n",
      "Epoch 358/600\n",
      "17/17 - 0s - loss: 0.1388 - val_loss: 0.0562\n",
      "Epoch 359/600\n",
      "17/17 - 0s - loss: 0.0504 - val_loss: 0.0583\n",
      "Epoch 360/600\n",
      "17/17 - 0s - loss: 0.0348 - val_loss: 0.0529\n",
      "Epoch 361/600\n",
      "17/17 - 0s - loss: 0.0302 - val_loss: 0.0312\n",
      "Epoch 362/600\n",
      "17/17 - 0s - loss: 0.0278 - val_loss: 0.0664\n",
      "Epoch 363/600\n",
      "17/17 - 0s - loss: 0.0222 - val_loss: 0.0304\n",
      "Epoch 364/600\n",
      "17/17 - 0s - loss: 0.0120 - val_loss: 0.0279\n",
      "Epoch 365/600\n",
      "17/17 - 0s - loss: 0.0162 - val_loss: 0.0856\n",
      "Epoch 366/600\n",
      "17/17 - 0s - loss: 0.0374 - val_loss: 0.0909\n",
      "Epoch 367/600\n",
      "17/17 - 0s - loss: 0.1146 - val_loss: 0.2086\n",
      "Epoch 368/600\n",
      "17/17 - 0s - loss: 0.0498 - val_loss: 0.0531\n",
      "Epoch 369/600\n",
      "17/17 - 0s - loss: 0.0165 - val_loss: 0.0420\n",
      "Epoch 370/600\n",
      "17/17 - 0s - loss: 0.0278 - val_loss: 0.0924\n",
      "Epoch 371/600\n",
      "17/17 - 0s - loss: 0.0330 - val_loss: 0.0328\n",
      "Epoch 372/600\n",
      "17/17 - 0s - loss: 0.0112 - val_loss: 0.0385\n",
      "Epoch 373/600\n",
      "17/17 - 0s - loss: 0.0188 - val_loss: 0.0852\n",
      "Epoch 374/600\n",
      "17/17 - 0s - loss: 0.0374 - val_loss: 0.0883\n",
      "Epoch 375/600\n",
      "17/17 - 0s - loss: 0.0475 - val_loss: 0.1355\n",
      "Epoch 376/600\n",
      "17/17 - 0s - loss: 0.0812 - val_loss: 0.2191\n",
      "Epoch 377/600\n",
      "17/17 - 0s - loss: 0.0637 - val_loss: 0.0392\n",
      "Epoch 378/600\n",
      "17/17 - 0s - loss: 0.0341 - val_loss: 0.0419\n",
      "Epoch 379/600\n",
      "17/17 - 0s - loss: 0.0242 - val_loss: 0.0607\n",
      "Epoch 380/600\n",
      "17/17 - 0s - loss: 0.0594 - val_loss: 0.1185\n",
      "Epoch 381/600\n",
      "17/17 - 0s - loss: 0.0644 - val_loss: 0.0486\n",
      "Epoch 382/600\n",
      "17/17 - 0s - loss: 0.0207 - val_loss: 0.0537\n",
      "Epoch 383/600\n",
      "17/17 - 0s - loss: 0.0205 - val_loss: 0.0323\n",
      "Epoch 384/600\n",
      "17/17 - 0s - loss: 0.0157 - val_loss: 0.0465\n",
      "Epoch 385/600\n",
      "17/17 - 0s - loss: 0.0180 - val_loss: 0.0293\n",
      "Epoch 386/600\n",
      "17/17 - 0s - loss: 0.0200 - val_loss: 0.0696\n",
      "Epoch 387/600\n",
      "17/17 - 0s - loss: 0.0293 - val_loss: 0.0430\n",
      "Epoch 388/600\n",
      "17/17 - 0s - loss: 0.0170 - val_loss: 0.0288\n",
      "Epoch 389/600\n",
      "17/17 - 0s - loss: 0.0114 - val_loss: 0.0327\n",
      "Epoch 390/600\n",
      "17/17 - 0s - loss: 0.0089 - val_loss: 0.0772\n",
      "Epoch 391/600\n",
      "17/17 - 0s - loss: 0.0350 - val_loss: 0.0865\n",
      "Epoch 392/600\n",
      "17/17 - 0s - loss: 0.0422 - val_loss: 0.0759\n",
      "Epoch 393/600\n",
      "17/17 - 0s - loss: 0.0498 - val_loss: 0.5678\n",
      "Epoch 394/600\n",
      "17/17 - 0s - loss: 0.4627 - val_loss: 0.3345\n",
      "Epoch 395/600\n",
      "17/17 - 0s - loss: 0.3394 - val_loss: 0.2195\n",
      "Epoch 396/600\n",
      "17/17 - 0s - loss: 0.2670 - val_loss: 0.0932\n",
      "Epoch 397/600\n",
      "17/17 - 0s - loss: 0.0706 - val_loss: 0.0969\n",
      "Epoch 398/600\n",
      "17/17 - 0s - loss: 0.0376 - val_loss: 0.0375\n",
      "Epoch 399/600\n",
      "17/17 - 0s - loss: 0.0321 - val_loss: 0.0499\n",
      "Epoch 400/600\n",
      "17/17 - 0s - loss: 0.0533 - val_loss: 0.0442\n",
      "Epoch 401/600\n",
      "17/17 - 0s - loss: 0.0214 - val_loss: 0.0308\n",
      "Epoch 402/600\n",
      "17/17 - 0s - loss: 0.0179 - val_loss: 0.0348\n",
      "Epoch 403/600\n",
      "17/17 - 0s - loss: 0.0131 - val_loss: 0.0322\n",
      "Epoch 404/600\n",
      "17/17 - 0s - loss: 0.0098 - val_loss: 0.0298\n",
      "Epoch 405/600\n",
      "17/17 - 0s - loss: 0.0132 - val_loss: 0.0236\n",
      "Epoch 406/600\n",
      "17/17 - 0s - loss: 0.0092 - val_loss: 0.0282\n",
      "Epoch 407/600\n",
      "17/17 - 0s - loss: 0.0122 - val_loss: 0.0376\n",
      "Epoch 408/600\n",
      "17/17 - 0s - loss: 0.0120 - val_loss: 0.0280\n",
      "Epoch 409/600\n",
      "17/17 - 0s - loss: 0.0123 - val_loss: 0.0327\n",
      "Epoch 410/600\n",
      "17/17 - 0s - loss: 0.0435 - val_loss: 0.0498\n",
      "Epoch 411/600\n",
      "17/17 - 0s - loss: 0.0620 - val_loss: 0.0442\n",
      "Epoch 412/600\n",
      "17/17 - 0s - loss: 0.0696 - val_loss: 0.0382\n",
      "Epoch 413/600\n",
      "17/17 - 0s - loss: 0.0300 - val_loss: 0.0424\n",
      "Epoch 414/600\n",
      "17/17 - 0s - loss: 0.0256 - val_loss: 0.0847\n",
      "Epoch 415/600\n",
      "17/17 - 0s - loss: 0.0309 - val_loss: 0.1060\n",
      "Epoch 416/600\n",
      "17/17 - 0s - loss: 0.0483 - val_loss: 0.0752\n",
      "Epoch 417/600\n",
      "17/17 - 0s - loss: 0.0884 - val_loss: 0.1843\n",
      "Epoch 418/600\n",
      "17/17 - 0s - loss: 0.2260 - val_loss: 0.1464\n",
      "Epoch 419/600\n",
      "17/17 - 0s - loss: 0.3858 - val_loss: 0.1080\n",
      "Epoch 420/600\n",
      "17/17 - 0s - loss: 0.1637 - val_loss: 0.0533\n",
      "Epoch 421/600\n",
      "17/17 - 0s - loss: 0.0595 - val_loss: 0.1093\n",
      "Epoch 422/600\n",
      "17/17 - 0s - loss: 0.0569 - val_loss: 0.1067\n",
      "Epoch 423/600\n",
      "17/17 - 0s - loss: 0.0435 - val_loss: 0.0590\n",
      "Epoch 424/600\n",
      "17/17 - 0s - loss: 0.0268 - val_loss: 0.0473\n",
      "Epoch 425/600\n",
      "17/17 - 0s - loss: 0.0207 - val_loss: 0.0348\n",
      "Epoch 426/600\n",
      "17/17 - 0s - loss: 0.0182 - val_loss: 0.0323\n",
      "Epoch 427/600\n",
      "17/17 - 0s - loss: 0.0137 - val_loss: 0.0314\n",
      "Epoch 428/600\n",
      "17/17 - 0s - loss: 0.0180 - val_loss: 0.0445\n",
      "Epoch 429/600\n",
      "17/17 - 0s - loss: 0.0116 - val_loss: 0.0405\n",
      "Epoch 430/600\n",
      "17/17 - 0s - loss: 0.0097 - val_loss: 0.0399\n",
      "Epoch 431/600\n",
      "17/17 - 0s - loss: 0.0160 - val_loss: 0.0320\n",
      "Epoch 432/600\n",
      "17/17 - 0s - loss: 0.0211 - val_loss: 0.0399\n",
      "Epoch 433/600\n",
      "17/17 - 0s - loss: 0.0569 - val_loss: 0.1361\n",
      "Epoch 434/600\n",
      "17/17 - 0s - loss: 0.0697 - val_loss: 0.3798\n",
      "Epoch 435/600\n",
      "17/17 - 0s - loss: 0.3594 - val_loss: 0.2605\n",
      "Epoch 436/600\n",
      "17/17 - 0s - loss: 0.0820 - val_loss: 0.0546\n",
      "Epoch 437/600\n",
      "17/17 - 0s - loss: 0.0315 - val_loss: 0.0517\n",
      "Epoch 438/600\n",
      "17/17 - 0s - loss: 0.0248 - val_loss: 0.0355\n",
      "Epoch 439/600\n",
      "17/17 - 0s - loss: 0.0312 - val_loss: 0.0546\n",
      "Epoch 440/600\n",
      "17/17 - 0s - loss: 0.0381 - val_loss: 0.0302\n",
      "Epoch 441/600\n",
      "17/17 - 0s - loss: 0.0339 - val_loss: 0.0279\n",
      "Epoch 442/600\n",
      "17/17 - 0s - loss: 0.0116 - val_loss: 0.0260\n",
      "Epoch 443/600\n",
      "17/17 - 0s - loss: 0.0111 - val_loss: 0.0259\n",
      "Epoch 444/600\n",
      "17/17 - 0s - loss: 0.0060 - val_loss: 0.0228\n",
      "Epoch 445/600\n",
      "17/17 - 0s - loss: 0.0097 - val_loss: 0.0409\n",
      "Epoch 446/600\n",
      "17/17 - 0s - loss: 0.0110 - val_loss: 0.0325\n",
      "Epoch 447/600\n",
      "17/17 - 0s - loss: 0.0130 - val_loss: 0.0267\n",
      "Epoch 448/600\n",
      "17/17 - 0s - loss: 0.0074 - val_loss: 0.0210\n",
      "Epoch 449/600\n",
      "17/17 - 0s - loss: 0.0052 - val_loss: 0.0272\n",
      "Epoch 450/600\n",
      "17/17 - 0s - loss: 0.0120 - val_loss: 0.0230\n",
      "Epoch 451/600\n",
      "17/17 - 0s - loss: 0.0087 - val_loss: 0.0294\n",
      "Epoch 452/600\n",
      "17/17 - 0s - loss: 0.0098 - val_loss: 0.0329\n",
      "Epoch 453/600\n",
      "17/17 - 0s - loss: 0.0272 - val_loss: 0.0407\n",
      "Epoch 454/600\n",
      "17/17 - 0s - loss: 0.0255 - val_loss: 0.0343\n",
      "Epoch 455/600\n",
      "17/17 - 0s - loss: 0.0132 - val_loss: 0.0252\n",
      "Epoch 456/600\n",
      "17/17 - 0s - loss: 0.0137 - val_loss: 0.0278\n",
      "Epoch 457/600\n",
      "17/17 - 0s - loss: 0.0178 - val_loss: 0.0589\n",
      "Epoch 458/600\n",
      "17/17 - 0s - loss: 0.1069 - val_loss: 0.3817\n",
      "Epoch 459/600\n",
      "17/17 - 0s - loss: 0.0878 - val_loss: 0.0597\n",
      "Epoch 460/600\n",
      "17/17 - 0s - loss: 0.0240 - val_loss: 0.0277\n",
      "Epoch 461/600\n",
      "17/17 - 0s - loss: 0.0134 - val_loss: 0.0245\n",
      "Epoch 462/600\n",
      "17/17 - 0s - loss: 0.0086 - val_loss: 0.0310\n",
      "Epoch 463/600\n",
      "17/17 - 0s - loss: 0.0124 - val_loss: 0.0190\n",
      "Epoch 464/600\n",
      "17/17 - 0s - loss: 0.0122 - val_loss: 0.0183\n",
      "Epoch 465/600\n",
      "17/17 - 0s - loss: 0.0339 - val_loss: 0.0756\n",
      "Epoch 466/600\n",
      "17/17 - 0s - loss: 0.1046 - val_loss: 0.0883\n",
      "Epoch 467/600\n",
      "17/17 - 0s - loss: 0.0618 - val_loss: 0.0785\n",
      "Epoch 468/600\n",
      "17/17 - 0s - loss: 0.1416 - val_loss: 0.1500\n",
      "Epoch 469/600\n",
      "17/17 - 0s - loss: 0.1107 - val_loss: 0.0838\n",
      "Epoch 470/600\n",
      "17/17 - 0s - loss: 0.1072 - val_loss: 0.1287\n",
      "Epoch 471/600\n",
      "17/17 - 0s - loss: 0.0965 - val_loss: 0.0532\n",
      "Epoch 472/600\n",
      "17/17 - 0s - loss: 0.1107 - val_loss: 0.2388\n",
      "Epoch 473/600\n",
      "17/17 - 0s - loss: 0.2113 - val_loss: 0.3244\n",
      "Epoch 474/600\n",
      "17/17 - 0s - loss: 0.0831 - val_loss: 0.0472\n",
      "Epoch 475/600\n",
      "17/17 - 0s - loss: 0.0557 - val_loss: 0.0835\n",
      "Epoch 476/600\n",
      "17/17 - 0s - loss: 0.0391 - val_loss: 0.0266\n",
      "Epoch 477/600\n",
      "17/17 - 0s - loss: 0.0215 - val_loss: 0.0336\n",
      "Epoch 478/600\n",
      "17/17 - 0s - loss: 0.0107 - val_loss: 0.0229\n",
      "Epoch 479/600\n",
      "17/17 - 0s - loss: 0.0086 - val_loss: 0.0243\n",
      "Epoch 480/600\n",
      "17/17 - 0s - loss: 0.0145 - val_loss: 0.0206\n",
      "Epoch 481/600\n",
      "17/17 - 0s - loss: 0.0125 - val_loss: 0.0418\n",
      "Epoch 482/600\n",
      "17/17 - 0s - loss: 0.0197 - val_loss: 0.0807\n",
      "Epoch 483/600\n",
      "17/17 - 0s - loss: 0.0422 - val_loss: 0.0366\n",
      "Epoch 484/600\n",
      "17/17 - 0s - loss: 0.0145 - val_loss: 0.0299\n",
      "Epoch 485/600\n",
      "17/17 - 0s - loss: 0.0164 - val_loss: 0.0386\n",
      "Epoch 486/600\n",
      "17/17 - 0s - loss: 0.0392 - val_loss: 0.0684\n",
      "Epoch 487/600\n",
      "17/17 - 0s - loss: 0.0224 - val_loss: 0.0248\n",
      "Epoch 488/600\n",
      "17/17 - 0s - loss: 0.0097 - val_loss: 0.0643\n",
      "Epoch 489/600\n",
      "17/17 - 0s - loss: 0.0214 - val_loss: 0.0288\n",
      "Epoch 490/600\n",
      "17/17 - 0s - loss: 0.0083 - val_loss: 0.0170\n",
      "Epoch 491/600\n",
      "17/17 - 0s - loss: 0.0055 - val_loss: 0.0207\n",
      "Epoch 492/600\n",
      "17/17 - 0s - loss: 0.0061 - val_loss: 0.0199\n",
      "Epoch 493/600\n",
      "17/17 - 0s - loss: 0.0067 - val_loss: 0.0183\n",
      "Epoch 494/600\n",
      "17/17 - 0s - loss: 0.0051 - val_loss: 0.0187\n",
      "Epoch 495/600\n",
      "17/17 - 0s - loss: 0.0069 - val_loss: 0.0288\n",
      "Epoch 496/600\n",
      "17/17 - 0s - loss: 0.0175 - val_loss: 0.0958\n",
      "Epoch 497/600\n",
      "17/17 - 0s - loss: 0.0379 - val_loss: 0.0695\n",
      "Epoch 498/600\n",
      "17/17 - 0s - loss: 0.0436 - val_loss: 0.0329\n",
      "Epoch 499/600\n",
      "17/17 - 0s - loss: 0.0147 - val_loss: 0.0275\n",
      "Epoch 500/600\n",
      "17/17 - 0s - loss: 0.0157 - val_loss: 0.0412\n",
      "Epoch 501/600\n",
      "17/17 - 0s - loss: 0.0289 - val_loss: 0.0261\n",
      "Epoch 502/600\n",
      "17/17 - 0s - loss: 0.0177 - val_loss: 0.0753\n",
      "Epoch 503/600\n",
      "17/17 - 0s - loss: 0.0480 - val_loss: 0.0589\n",
      "Epoch 504/600\n",
      "17/17 - 0s - loss: 0.0343 - val_loss: 0.0814\n",
      "Epoch 505/600\n",
      "17/17 - 0s - loss: 0.0401 - val_loss: 0.0425\n",
      "Epoch 506/600\n",
      "17/17 - 0s - loss: 0.0140 - val_loss: 0.0206\n",
      "Epoch 507/600\n",
      "17/17 - 0s - loss: 0.0233 - val_loss: 0.0271\n",
      "Epoch 508/600\n",
      "17/17 - 0s - loss: 0.0265 - val_loss: 0.0282\n",
      "Epoch 509/600\n",
      "17/17 - 0s - loss: 0.0215 - val_loss: 0.0260\n",
      "Epoch 510/600\n",
      "17/17 - 0s - loss: 0.0159 - val_loss: 0.0257\n",
      "Epoch 511/600\n",
      "17/17 - 0s - loss: 0.0151 - val_loss: 0.0271\n",
      "Epoch 512/600\n",
      "17/17 - 0s - loss: 0.0288 - val_loss: 0.0276\n",
      "Epoch 513/600\n",
      "17/17 - 0s - loss: 0.0158 - val_loss: 0.0171\n",
      "Epoch 514/600\n",
      "17/17 - 0s - loss: 0.0130 - val_loss: 0.0364\n",
      "Epoch 515/600\n",
      "17/17 - 0s - loss: 0.0221 - val_loss: 0.0516\n",
      "Epoch 516/600\n",
      "17/17 - 0s - loss: 0.0399 - val_loss: 0.0667\n",
      "Epoch 517/600\n",
      "17/17 - 0s - loss: 0.0411 - val_loss: 0.0517\n",
      "Epoch 518/600\n",
      "17/17 - 0s - loss: 0.0310 - val_loss: 0.1019\n",
      "Epoch 519/600\n",
      "17/17 - 0s - loss: 0.0297 - val_loss: 0.1500\n",
      "Epoch 520/600\n",
      "17/17 - 0s - loss: 0.0435 - val_loss: 0.0337\n",
      "Epoch 521/600\n",
      "17/17 - 0s - loss: 0.0135 - val_loss: 0.0433\n",
      "Epoch 522/600\n",
      "17/17 - 0s - loss: 0.1745 - val_loss: 0.3735\n",
      "Epoch 523/600\n",
      "17/17 - 0s - loss: 0.2804 - val_loss: 0.2855\n",
      "Epoch 524/600\n",
      "17/17 - 0s - loss: 0.6846 - val_loss: 0.1791\n",
      "Epoch 525/600\n",
      "17/17 - 0s - loss: 0.4293 - val_loss: 0.1204\n",
      "Epoch 526/600\n",
      "17/17 - 0s - loss: 0.2565 - val_loss: 0.3892\n",
      "Epoch 527/600\n",
      "17/17 - 0s - loss: 0.1166 - val_loss: 0.1373\n",
      "Epoch 528/600\n",
      "17/17 - 0s - loss: 0.0713 - val_loss: 0.0581\n",
      "Epoch 529/600\n",
      "17/17 - 0s - loss: 0.0272 - val_loss: 0.0333\n",
      "Epoch 530/600\n",
      "17/17 - 0s - loss: 0.0196 - val_loss: 0.0617\n",
      "Epoch 531/600\n",
      "17/17 - 0s - loss: 0.0207 - val_loss: 0.0385\n",
      "Epoch 532/600\n",
      "17/17 - 0s - loss: 0.0218 - val_loss: 0.0294\n",
      "Epoch 533/600\n",
      "17/17 - 0s - loss: 0.0174 - val_loss: 0.0369\n",
      "Epoch 534/600\n",
      "17/17 - 0s - loss: 0.0154 - val_loss: 0.0440\n",
      "Epoch 535/600\n",
      "17/17 - 0s - loss: 0.0271 - val_loss: 0.0438\n",
      "Epoch 536/600\n",
      "17/17 - 0s - loss: 0.0167 - val_loss: 0.0359\n",
      "Epoch 537/600\n",
      "17/17 - 0s - loss: 0.0130 - val_loss: 0.0288\n",
      "Epoch 538/600\n",
      "17/17 - 0s - loss: 0.0102 - val_loss: 0.0243\n",
      "Epoch 539/600\n",
      "17/17 - 0s - loss: 0.0075 - val_loss: 0.0226\n",
      "Epoch 540/600\n",
      "17/17 - 0s - loss: 0.0088 - val_loss: 0.0308\n",
      "Epoch 541/600\n",
      "17/17 - 0s - loss: 0.0171 - val_loss: 0.0295\n",
      "Epoch 542/600\n",
      "17/17 - 0s - loss: 0.0180 - val_loss: 0.0205\n",
      "Epoch 543/600\n",
      "17/17 - 0s - loss: 0.0098 - val_loss: 0.0334\n",
      "Epoch 544/600\n",
      "17/17 - 0s - loss: 0.0086 - val_loss: 0.0164\n",
      "Epoch 545/600\n",
      "17/17 - 0s - loss: 0.0065 - val_loss: 0.0165\n",
      "Epoch 546/600\n",
      "17/17 - 0s - loss: 0.0061 - val_loss: 0.0264\n",
      "Epoch 547/600\n",
      "17/17 - 0s - loss: 0.0085 - val_loss: 0.0195\n",
      "Epoch 548/600\n",
      "17/17 - 0s - loss: 0.0078 - val_loss: 0.0239\n",
      "Epoch 549/600\n",
      "17/17 - 0s - loss: 0.0241 - val_loss: 0.0236\n",
      "Epoch 550/600\n",
      "17/17 - 0s - loss: 0.0218 - val_loss: 0.0689\n",
      "Epoch 551/600\n",
      "17/17 - 0s - loss: 0.0460 - val_loss: 0.0675\n",
      "Epoch 552/600\n",
      "17/17 - 0s - loss: 0.0461 - val_loss: 0.0341\n",
      "Epoch 553/600\n",
      "17/17 - 0s - loss: 0.0476 - val_loss: 0.0623\n",
      "Epoch 554/600\n",
      "17/17 - 0s - loss: 0.0460 - val_loss: 0.0620\n",
      "Epoch 555/600\n",
      "17/17 - 0s - loss: 0.0278 - val_loss: 0.0452\n",
      "Epoch 556/600\n",
      "17/17 - 0s - loss: 0.0203 - val_loss: 0.0554\n",
      "Epoch 557/600\n",
      "17/17 - 0s - loss: 0.0220 - val_loss: 0.0633\n",
      "Epoch 558/600\n",
      "17/17 - 0s - loss: 0.0683 - val_loss: 0.0404\n",
      "Epoch 559/600\n",
      "17/17 - 0s - loss: 0.0800 - val_loss: 0.1603\n",
      "Epoch 560/600\n",
      "17/17 - 0s - loss: 0.1114 - val_loss: 0.1495\n",
      "Epoch 561/600\n",
      "17/17 - 0s - loss: 0.0461 - val_loss: 0.0941\n",
      "Epoch 562/600\n",
      "17/17 - 0s - loss: 0.0335 - val_loss: 0.0375\n",
      "Epoch 563/600\n",
      "17/17 - 0s - loss: 0.0223 - val_loss: 0.0477\n",
      "Epoch 564/600\n",
      "17/17 - 0s - loss: 0.0200 - val_loss: 0.0338\n",
      "Epoch 565/600\n",
      "17/17 - 0s - loss: 0.0125 - val_loss: 0.0177\n",
      "Epoch 566/600\n",
      "17/17 - 0s - loss: 0.0091 - val_loss: 0.0200\n",
      "Epoch 567/600\n",
      "17/17 - 0s - loss: 0.0066 - val_loss: 0.0162\n",
      "Epoch 568/600\n",
      "17/17 - 0s - loss: 0.0073 - val_loss: 0.0284\n",
      "Epoch 569/600\n",
      "17/17 - 0s - loss: 0.0126 - val_loss: 0.0367\n",
      "Epoch 570/600\n",
      "17/17 - 0s - loss: 0.0142 - val_loss: 0.0412\n",
      "Epoch 571/600\n",
      "17/17 - 0s - loss: 0.0295 - val_loss: 0.0315\n",
      "Epoch 572/600\n",
      "17/17 - 0s - loss: 0.0072 - val_loss: 0.0200\n",
      "Epoch 573/600\n",
      "17/17 - 0s - loss: 0.0089 - val_loss: 0.0916\n",
      "Epoch 574/600\n",
      "17/17 - 0s - loss: 0.0615 - val_loss: 0.0601\n",
      "Epoch 575/600\n",
      "17/17 - 0s - loss: 0.0230 - val_loss: 0.0225\n",
      "Epoch 576/600\n",
      "17/17 - 0s - loss: 0.0128 - val_loss: 0.0202\n",
      "Epoch 577/600\n",
      "17/17 - 0s - loss: 0.0111 - val_loss: 0.0239\n",
      "Epoch 578/600\n",
      "17/17 - 0s - loss: 0.0204 - val_loss: 0.0224\n",
      "Epoch 579/600\n",
      "17/17 - 0s - loss: 0.0107 - val_loss: 0.0382\n",
      "Epoch 580/600\n",
      "17/17 - 0s - loss: 0.0254 - val_loss: 0.0317\n",
      "Epoch 581/600\n",
      "17/17 - 0s - loss: 0.0251 - val_loss: 0.0414\n",
      "Epoch 582/600\n",
      "17/17 - 0s - loss: 0.0277 - val_loss: 0.0278\n",
      "Epoch 583/600\n",
      "17/17 - 0s - loss: 0.0265 - val_loss: 0.0315\n",
      "Epoch 584/600\n",
      "17/17 - 0s - loss: 0.0155 - val_loss: 0.0178\n",
      "Epoch 585/600\n",
      "17/17 - 0s - loss: 0.0082 - val_loss: 0.0164\n",
      "Epoch 586/600\n",
      "17/17 - 0s - loss: 0.0101 - val_loss: 0.0157\n",
      "Epoch 587/600\n",
      "17/17 - 0s - loss: 0.0066 - val_loss: 0.0154\n",
      "Epoch 588/600\n",
      "17/17 - 0s - loss: 0.0075 - val_loss: 0.0253\n",
      "Epoch 589/600\n",
      "17/17 - 0s - loss: 0.0085 - val_loss: 0.0240\n",
      "Epoch 590/600\n",
      "17/17 - 0s - loss: 0.0093 - val_loss: 0.0191\n",
      "Epoch 591/600\n",
      "17/17 - 0s - loss: 0.0096 - val_loss: 0.0279\n",
      "Epoch 592/600\n",
      "17/17 - 0s - loss: 0.0206 - val_loss: 0.0287\n",
      "Epoch 593/600\n",
      "17/17 - 0s - loss: 0.0124 - val_loss: 0.0153\n",
      "Epoch 594/600\n",
      "17/17 - 0s - loss: 0.0230 - val_loss: 0.0259\n",
      "Epoch 595/600\n",
      "17/17 - 0s - loss: 0.0145 - val_loss: 0.0306\n",
      "Epoch 596/600\n",
      "17/17 - 0s - loss: 0.0688 - val_loss: 0.0347\n",
      "Epoch 597/600\n",
      "17/17 - 0s - loss: 0.1146 - val_loss: 0.1403\n",
      "Epoch 598/600\n",
      "17/17 - 0s - loss: 0.3123 - val_loss: 0.3846\n",
      "Epoch 599/600\n",
      "17/17 - 0s - loss: 0.0994 - val_loss: 0.1562\n",
      "Epoch 600/600\n",
      "17/17 - 0s - loss: 0.0962 - val_loss: 0.2623\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "                    x_train, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=2, epochs=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxrElEQVR4nO3dd3hc1bXw4d+a0ajLcpcrLtgYXMBgUQPGAlNDCST5MCWXkguhOyQhxJcUkhsCF+4lIQ1CCC0UQ2ghQAgELIwpBtvY2MZgG9zkJku2LI3KaMr6/jijZpUZS5o5kma9z6Nnztmnre2yZmufffYRVcUYY0zq8LgdgDHGmOSyxG+MMSnGEr8xxqQYS/zGGJNiLPEbY0yKSXM7gHgMHjxYx44d26ljw6Vr8Yaq2Zg2HvWkMW5wTvcGl0TV1dXk5PTe+JuzuvQ8faUeYHVpsHTp0jJVHbJvea9I/GPHjmXJkiWdOvbTp3/O5DX38IOCX7GBkTx3zXHdHF3yFBcXM2vWLLfD6BZWl56nr9QDrC4NRGRTW+V9vqsnlJYHwECpoS4YdjkaY4xxX59P/EFfLgD9pYpAKOJyNMYY474USPxOi78/fgIha/EbY0yv6OPvioaunn74qQtai9+Y3iQYDFJSUkJdXd1+HZefn8+aNWsSFFVyxVOXzMxMRo0ahc/ni+ucKZD4swDIoYaA9fEb06uUlJSQl5fH2LFjEZG4j6uqqiIvLy+BkSVPrLqoKuXl5ZSUlDBu3Li4ztnnu3oQL/hyyNFaa/Eb08vU1dUxaNCg/Ur6qUZEGDRo0H79VtT3Ez9ARh5H7XiS0ZEtBMOW/I3pTSzpx7a/f0apkfgDVQA84LuH6kDI5WCMMcZdqZH41enbD+Glut76+Y0x8cnNzXU7hITo8zd3AQg5fV+VZCPW4jfGpLiEtfhF5CERKRWRVW1s+4GIqIgMTtT121Kl2fgt8Rtj9pOqcvPNNzN16lSmTZvG008/DcD27duZOXMm06dPZ+rUqbzzzjuEw2Euu+yyxn1//etfuxx9a4ls8T8C/B54rHmhiIwGTgE2J/Dabaokm/SAdfUY0xv9/B+r+XRbZVz7hsNhvF5vzP0mj+jHz86eEnO/559/nuXLl7NixQrKyso48sgjmTlzJk8++SSnnXYat956K+FwmJqaGpYvX87WrVtZtcpp81ZUVMQVczIlrMWvqguB3W1s+jXwQyB5L/sddigAQU2zFr8xZr8tWrSICy+8EK/XS0FBASeeeCIfffQRRx55JA8//DC33XYbK1euJC8vj/Hjx/Pll19yww038Nprr9GvXz+3w28lqX38InIOsFVVV8QafiQiVwFXARQUFFBcXNypa/r9fhYdeAvH77iYdAmxdMVKMss+69S53Ob3+zv959DTWF16np5Yj/z8fKqqnFF535t1QNzHxdviBxrP39H2QCBAXV1d477BYJDa2lqKiop49dVX+de//sXFF1/MjTfeyEUXXcSiRYt48803uffee3niiSf44x//GHfsbdUlVozgPPMQ99+fqibsBxgLrIouZwOLgfzo+kZgcDznmTFjhnbWggULVFU1+Luj9Y0fn6jziz/u9Lnc1lCXvsDq0vP0xHp8+umnnTqusrKyW66fk5OjqqrPPfecnnrqqRoKhbS0tFQPOOAA3b59u27cuFGDwaCqqv7617/WuXPn6q5du3Tv3r2qqvrxxx/rYYcd1qUY4q1LW39WwBJtI6cms8V/IDAOaGjtjwKWichRqroj0Rf3+LKY7V0GC06EE/cm+nLGmD7kvPPO4/333+ewww5DRLjrrrsYNmwYjz76KHfffTc+n4/c3Fwee+wxtm7dyuWXX04k4jwsescdd7gcfWtJS/yquhIY2rAuIhuBQlUtS8b1Pb7MppVwCLypMZLVGNN5fr8fcJ6Mvfvuu7n77rtbbL/00ku59NJLWx23bNmypMTXWYkczvkU8D4wSURKROTbibpWXNLSm5ZDte7FYYwxLktYs1dVL4yxfWyirt2mtKYWfyhQS1pG35i5zxhj9ldqTNkA4G1q8Zfs2uNiIMYY467USfzNWvwbdiTltoIxxvRIKZT4MxoXt5XZqB5jTOpKycQfqK12MRBjjHFXCiX+pq6e+kCNi4EYY4y7Uifx+7IbF0OW+I0xCdDR/P0bN25k6tSpSYymfamT+DObJkoKBWwcvzEmdaXO46sZTYk/XG+J35he558/gh0r49o1K96n84dNgzPubHfzLbfcwpgxY7j22msBuO222xARFi5cyJ49ewgGg/zyl7/k3HPPjSuuBnV1dVxzzTUsWbKEtLQ07rnnHoqKili9ejWXX3459fX1RCIRnnvuOfLy8pgzZw4lJSWEw2F+8pOfcMEFF+zX9faVOok/M79xMRy0xG+MiW3OnDl897vfbUz8zzzzDK+99ho33XQT/fr1o6ysjGOOOYZzzjlnv154/oc//AGAlStX8tlnn3Hqqaeydu1a7r//fubOncvFF19MfX094XCY5557jhEjRvDKK68AsHdv10clplDib2rxa32di4EYYzqlg5b5vmqrqsjL6/rT+YcffjilpaVs27aNXbt2MWDAAIYPH85NN93EwoUL8Xg8bN26lZ07dzJs2LC4z7to0SJuuOEGAA4++GDGjBnD2rVrOfbYY7n99tspKSnh/PPPZ+LEiUyePJmf/OQn3HLLLZx11lmccMIJXa5X6vTxZzS1+BvewWuMMbF84xvf4Nlnn+Xpp59mzpw5PPHEE+zatYulS5eyfPlyCgoKqKvbv5zizJjc2kUXXcRLL71EVlYWp512Gm+99RYTJ05k6dKlTJs2jXnz5vGLX/yiy3VKyRa/JxygPhQhPS11vveMMZ0zZ84crrzySsrKynj77bd55plnGDp0KD6fjwULFrBp06b9PufMmTN54oknOOmkk1i7di2bN29m0qRJfPnll4wfP54bb7yRL7/8kk8++YRRo0ZxwAEHcMkll5Cbm8sjjzzS5TqlTuJvdnM3Q+qpqK1naF5mBwcYYwxMmTKFqqoqRo4cyfDhw7n44os5++yzKSwsZPr06Rx88MH7fc5rr72Wq6++mmnTppGWlsYjjzxCRkYGTz/9NI8//jg+n49hw4bx05/+lLfffptvfOMbeDwefD4f9913X5frlDqJv1mLP5Mge6qDlviNMXFZubJpNNHgwYN5//3329yvYf7+towdO7bxBeyZmZltttznzZvHvHnzWpTNnj2b8847rxNRty91+jp8WXDjx4TTssmgnt3V9W5HZIwxrkidFj/AwPFEMvqRWRekosYSvzGm+61cuZJvfetbLcoyMjJYvHixSxG1llqJH5C0TDKknt2W+I3pFVR1v8bIu23atGksX748qddsb5RQe1KnqyfKk55FJkF2+y3xG9PTZWZmUl5evt+JLZWoKuXl5WRmxn/PMuVa/B5fJtmeIJV1QbdDMcbEMGrUKEpKSti1a9d+HVdXV7dfibAni6cumZmZjBo1Ku5zplziJy2LbE8llbUhtyMxxsTg8/kYN27cfh9XXFzM4YcfnoCIki8RdUlYV4+IPCQipSKyqlnZ3SLymYh8IiIviEj/RF2/XWkZ1uI3xqS0RPbxPwKcvk/ZG8BUVT0UWAvM2/eghPNlkSmW+I0xqSthiV9VFwK79yl7XVUb+lg+AOLvlOouaRlkEbSuHmNMypJE3i0XkbHAy6ra6rUzIvIP4GlVfbydY68CrgIoKCiYMX/+/E7F4Pf7W7wV5+A1v8G7axVf5bfcNTO7gyN7nn3r0ptZXXqevlIPsLo0KCoqWqqqhfuWu3JzV0RuBULAE+3to6oPAA8AFBYW6qxZszp1reLiYlocW/Ui/vLlBCNpdPacbmlVl17M6tLz9JV6gNUllqQnfhG5FDgLOFndGJyblkluaA8jgl/0ugdDjDGmOyT1AS4ROR24BThHVd154/m2jwGY5/krgVDElRCMMcZNiRzO+RTwPjBJREpE5NvA74E84A0RWS4i9yfq+u06+jsAbNYCauvDSb+8Mca4LWFdPap6YRvFf0nU9eI29Xxq/3EzhJSaYJgBbsdjjDFJlnJz9QBEvFlkSb21+I0xKSk1E39aFlnUUxe0xG+MST0pmfjVl0UWAWot8RtjUlBKJn7xZZEp9dRYV48xJgWlZOLHl+20+C3xG2NSUEomfkm3Pn5jTOpKycTvSc8mSwLW1WOMSUkpmfi9GTlkUm83d40xKSlFE7/Tx29dPcaYVJSaiT89myzqqbaXsRhjUlDqvXMXkPRsRJSq6mq3QzHGmKRLyRY/PucFLH5/pcuBGGNM8qVo4s8CoNpf5XIgxhiTfCma+J0Wf22N3+VAjDEm+VI08Tst/jpL/MaYFJTSiT8cqCEYtrdwGWNSS4omfqerxyZqM8akohRN/E6L3x7iMsakohRN/E6L3yZqM8akohRN/NEWv9jLWIwxqSdhiV9EHhKRUhFZ1axsoIi8ISLrop/uvOu8oY+feuqCdnPXGJNaEtnifwQ4fZ+yHwFvqupE4M3oevI16+O3l7EYY1JNwhK/qi4Edu9TfC7waHT5UeBribp+h9IaEr/18RtjUo+oauJOLjIWeFlVp0bXK1S1f7Pte1S1ze4eEbkKuAqgoKBgxvz58zsVg9/vJzc3t1X58Qv/Hw/Xn0zF1G9z5LDeMVdde3XpjawuPU9fqQdYXRoUFRUtVdXCfct7bMZT1QeABwAKCwt11qxZnTpPcXExbR0b+mgA/eprGHTQwcw6YlQXIk2e9urSG1ldep6+Ug+wusSS7FE9O0VkOED0szTJ12+kmfnkS7WN6jHGpJxkJ/6XgEujy5cCf0/y9RtJ1gD6UW2jeowxKSeRwzmfAt4HJolIiYh8G7gTOEVE1gGnRNddIVlOi99u7hpjUk3C+vhV9cJ2Np2cqGvuD09Wf0v8xpiUlJpP7uJ09eRTbeP4jTEpJ2UTP5n9yZNa6urr3Y7EGGOSKnUTf8Oc/PV1LgdijDHJlbqJ3+sDIGgtfmNMiunw5q6IfBLHOXapao+4YbtfPNHEHwy4HIgxxiRXrFE9XuDMDrYLztj83sfrVD0YtBa/MSa1xEr831HVTR3tICLXdmM8yeNxqh6yFr8xJsV02MevqotinSCefXqkaFdPKBh0ORBjjEmuDhO/iJwrItc1W18sIl9Gf76Z+PASKHpzNxyyrh5jTGqJNarnh7Tsw88AjgRmAVcnKKbkiHb1hG1UjzEmxcTq409X1S3N1hepajlQLiI5CYwr8aIt/lDYunqMMaklVou/xUtSVPX6ZqtDuj+cJIr28YdtVI8xJsXESvyLReTKfQtF5DvAh4kJKUmiwzk1HCQSSdxbyIwxpqeJ1dVzE/CiiFwELIuWzcDp6/9aAuNKvGiL3ydhAqEIWelelwMyxpjk6DDxq2opcJyInARMiRa/oqpvJTyyRIv28acRJhAKW+I3xqSMWFM2ZOKM3pkArAT+oqqhZASWcJ7mid/ewmWMSR2x+vgfBQpxkv4ZwP8mPKJkifbx+wjZy1iMMSklVh//ZFWdBiAif6G339Btzlr8xpgUFavF3zjIvc908TRo3sdvL1w3xqSQWC3+w0SkMrosQFZ0XQBV1X4JjS6RPA1dPc7NXWOMSRWxRvUkZKiLiNwE/CegOPcPLlfV5L4Kq6HFL9bVY4xJLbEmaRvY0U9nLigiI4EbgUJVnYoz5/+czpyrSzxNN3etxW+MSSWxunrKgBKgoX9fmm1TYHwXrpslIkEgG9jWyfN0XrObu3XWx2+MSSGi2v50BSJyL85MnO8CT+FM0tbl+Q1EZC5wO1ALvK6qF7exz1XAVQAFBQUz5s+f36lr+f1+cnNzW5V7Q9WcsOgi/jt4Md4p53PciFjfge5rry69kdWl5+kr9QCrS4OioqKlqlrYaoOqdviD08ovAh4AlgN3AeNiHdfB+QYAb+FM8uYDXgQu6eiYGTNmaGctWLCg7Q2BatWf9dM7/usqfWrxpk6fP5narUsvZHXpefpKPVStLg2AJdpGTo01nJOGa+PMzX8/cDkwu1NfP47ZwAZV3aWqQeB54LgunK9zvDaO3xiTmmJN2ZADnAtcgNNCfx44QlvO0b+/NgPHiEg2TlfPycCSLpyvcxpu7ooN5zTGpJZYHdulwDqc/v31ODd0jxSRIwFU9fn9vaCqLhaRZ3Fm+wwBH+N0IyWXCOpJI40Qv3r1M7ZV1HHbOVNiH2eMMb1crMT/N5xkf3D0pznF+Q1gv6nqz4CfdebY7iTeDDKiDyc/8t5GS/zGmJQQ6wGuy5IUhzsy8sipTe5zY8YY47ZYD3CdFesE8ezTY2XkcqJ3BUPY43YkxhiTNLG6eu4Wka20fHBrX78CXu6+kJIoI48Rsp4XM37KVwK/czsaY4xJiliJfydwT4x91nVTLMkXHdkzUsrxejr6bjPGmL4jVh//rCTF4Y5QoHExy2evXjTGpIaYD3D1aeHG1w00PFVsjDF9Xoon/noAQp4MquvDhCOW/I0xfV/MxC8iHhFJ/pQKydAs8QP4A33rJWPGGNOWeObqiQD/l4RYki9rAAAZIT/nexZSWmlj+o0xfV+8XT2vi8jXRaRvDX2Z8yQAQoR70u9n57YNLgdkjDGJF2/i/x7O9A31IlIpIlXN3sXbe/UfDTMua1wtLd/rXizGGJMkcb19RFXzEh2Ia3w5jYs7y3e7GIgxxiRH3K+dEpFzgJnR1WJV7Z1P6+7L0/RLz6cbt6Gq9LUeLWOMaS6urh4RuROYC3wa/ZkbLev9tq9oXKzYW8HOykAHOxtjTO8Xbx//mcApqvqQqj4EnB4t6/2Ou7FxMZsAO2xkjzGmj9ufB7j6N1vO7+Y43DPxFLhhGQDZ1NmQTmNMnxdvH/+vgI9FZAHOTJ0zgXkJiyrZ0p032GdLgNIq6+oxxvRtMRO/iHiACHAMcCRO4r9FVXckOLbkSXdG9uRIHZ6tS2APMGCMuzEZY0yCxEz8qhoRketV9RngpSTElHy+bACGpIe4aOUVsBK4zcb0G2P6pnj7+N8QkR+IyGgRGdjwk9DIksnjAV82ReNz3Y7EGGMSLt7EfwVwHbAQWBr9WdLZi4pIfxF5VkQ+E5E1InJsZ8/VbTLymJDXNE3zz/+xmmA44mJAxhiTGHHNzgn8SFXH7fMzvgvXvRd4TVUPBg4D1nThXN0jfzSUNb1M7OF3N7Jyq3X3GGP6nnhn57yuuy4oIv1wRgX9JXr+elWt6K7zd9rAcbBzVYuiUnuYyxjTB0k8b54SkZ8AtcDTQHVDuaru9+Q2IjIdeADnCeDDcLqN5qpq9T77XQVcBVBQUDBj/vz5+3spAPx+P7m5sfvux254grGbnmlar3uSCw9O57Sxvk5dNxHirUtvYHXpefpKPcDq0qCoqGipqhbuWx7vOP4rop/NW/4KdKa7Jw04ArhBVReLyL3Aj4CfNN9JVR/A+YKgsLBQZ82a1YlLQXFxMXEdO2AnNEv8h/q2Up1xJEdnf0JWfgFMOr1T1+9OcdelF7C69Dx9pR5gdYkl3tk5x3XjNUuAElVdHF1/Fifxu2vE9BarL3lv5sKVt5L1+e1OgQ3vNMb0ER328YvID5stf3Ofbb/qzAWjD35tEZFJ0aKTcbp93DVoQquiG7wvuBCIMcYkVqybu3OaLe87RUNX+j5uAJ4QkU+A6ThTQrjL421VdJzX/e8jY4zpbrESv7Sz3NZ63FR1uaoWquqhqvo1Vd3T2XN1q+xBzufZv4Wbv6AsY7S78RhjTALESvzaznJb673f6dFXDEw+F3IGU5c5xN14jDEmAWLd3D0s+m5dAbKavWdXgMyERuaGQ/+f8xOVltY0lFODtej2lXgOOMqNyIwxptt02OJXVa+q9lPVPFVNiy43rPecAe4J4kvPaFxe8fh/4XnoFBa/+qiLERljTNftz4tYUk6/7KzG5embHgLgnQ8Wt7e7Mcb0Cpb4O+BLT29VVm8TtxljejlL/B1Jb/2YtAA19aHkx2KMMd3EEn9HTv0lOr6oVfGW8hpY/QJEwi4EZYwxXWOJvyM5g5Hz/tS6fMWT8LfLYMlDSQ/JGGO6yhJ/LJn5LVa9hEnb84WzUluR/HiMMaaLLPHH4mv5uEKW1KOBKmclI8+FgIwxpmvinZbZRN2Q9iLl5dH55dJz3A3GGGM6wVr8nTCo6nNnIWKje4wxvY8l/ngce33b5SF7NaMxpvexxB+P025vszgUrE1yIMYY03WW+Ltg6Rc73A7BGGP2myX+Lti4YzfhSN+bndoY07dZ4o/Xf22HW3c2rgbUx15/Nfe+uc55gtee4jXG9BKW+OOVnt1iTH81GWRQz33F64k8OBt+MdDF4IwxJn6W+DupHh8ZBAmGFc+2ZW6HY4wxcbPEv78OPIlF4SkE1Mcs7wpO8SxxOyJjjNkvriV+EfGKyMci8rJbMXTKt16g/Ot/I0gaw2QPf06/x+2IjDFmv7jZ4p8LrHHx+p127vSRTPBsczsMY4zpFFcSv4iMAr4KPOjG9RMmHHQ7AmOMiUlUkz8OXUSeBe4A8oAfqOpZbexzFXAVQEFBwYz58+d36lp+v5/c3NZv0uqqWcXntip75/gnCaclbuK2RNXFDVaXnqev1AOsLg2KioqWqmrhvuVJn51TRM4CSlV1qYjMam8/VX0AeACgsLBQZ81qd9cOFRcX09ljO/T5YVC2DoI1jUUnHD0D8oZ1/7WiElYXF1hdep6+Ug+wusTiRlfPV4BzRGQjMB84SUQedyGOrrmyGH60uWVZsy8BY4zpqZKe+FV1nqqOUtWxwBzgLVW9JNlxdJnHA14f4eZ/hDZpmzGmF7Bx/F3U4g6JJX5jTC/g6hu4VLUYKHYzhq5KI9K0Uu+HcAi89mIzY0zPZS3+LiodcVLjsj72NbjzAPeCMcaYOFji76KhVz7P3450hpoKCsFqp9VvjDE9lCX+rhIhbfhU3g1PaSrbu7n9/Y0xxmWW+LtBXmY6Nwavp0YznILyL90NyBhjOmCJvxuMGZRNOfmcGPi1U7DiSVj2mLtBGWNMOyzxd4OJBXm8fMPx7CKfoDcbVj0HL93gdljGGNMmS/zdZPLwfqSneSnPGNVU6MI8SMYYE4sl/m7i8Qij+mex1TOiqfDn/Z3WvzHG9CCW+LvRyAFZLKkf07LwrV+6E4wxxrTDEn83mjoyn/f8+8zOqZHWO277GF692bqCjDGusMTfjS45ZgyLIlNZE2n29G5bif/hr8KHD0CgMnnBGWNMlCX+bjSyfxYPXnYMtwUvbSqMtJH4G7eFEx+UMcbswxJ/NztkeD+qyGoq8O9sPYWDiPMZqkteYMYYE2WJv5sNy89kzPCCpoJIECo2tb2zJX5jjAss8SfA4dOm8kb4CKqKoiN6yta1vWMokLygjDEmyhJ/Ahw7cThXBn/AO1nRKZt3f9H2jtbiN8a4wBJ/AhwyPI9Mn4clOwBfDlRug80fwBs/bbljqN6V+Iwxqc1eFZUAaV4PU0bks3LbXjRnMPL+7+H93zsbT7ylaUdr8RtjXGAt/gQ54oD+fLRxDzUVO1tuqNgCNIzqsT5+Y0zyWeJPkDlHOQ9x5bBPq37vlqZla/EbY1yQ9MQvIqNFZIGIrBGR1SIyN9kxJMOBQ3L58VcP4dr6G6kafmzThopmb+eyFr8xxgVutPhDwPdV9RDgGOA6EZnsQhwJV3TwUF6NHMMPc25n3qR/gnitxW+McV3Sb+6q6nZge3S5SkTWACOBT5MdS6KNGZjNoJx0/rlqBwD/PXQkaRWW+I0x7hJ1cYZIERkLLASmqmrlPtuuAq4CKCgomDF//vxOXcPv95Obm9vFSDvviTUB3tjkTNmwcODt5KdFyKneSFq4lvUHXkHJ6HPjPpfbdelOVpeep6/UA6wuDYqKipaqauG+5a4N5xSRXOA54Lv7Jn0AVX0AeACgsLBQZ82a1anrFBcX09lju8PACRW88ft3AdidNYYDyl8Fjw+ACWNGMmFmNDb/LvhkPhx7fdNcPvtwuy7dyerS8/SVeoDVJRZXRvWIiA8n6T+hqs+7EUOyTBuZz/98fRqTCvJY7B/iFEaCzufSR5p2/Pt18PqPYfvyZIdojEkxbozqEeAvwBpVvSfZ1082EeGCIw/gnOkj+J+9pxAeOq1p494tULvHWa7b63wGrd/fGJNYbrT4vwJ8CzhJRJZHf850IY6kOnBILhE8fHnMfxM67BL+O3ixs8G/y/n0RHvdwjaNgzEmsdwY1bOIxkdXU8eEoTkArJaDyDzxbtZ89DtnQ/Uup+tn0yJnvd7vUoTGmFRhc/UkyQEDc8hI8/DKyu2s3LqXcu3nbKjYDP9o9gxbnb2O0RiTWJb4kyQ9zcPsyQW88sl2AAaT72x48WrIzG/aMdXfw1u31xn1lJ7tdiTG9Fk2V08SfffkiY3Lu8lr2tBwYxesxX/nAfDHY9yOwpg+zRJ/Ek0syGPRLUUARPDw9/BxrXcK7G1dlmrae1WlMaZbWOJPspH9s5g83Onfnxu8nq0yrOUOdZb4jTGJZYk/yUSEV+eewHEHDgLgpOA9kNGsj79qZztHGmNM97DE75LbzpkCQCAEZdd/3lheXb6lvUOMMaZbWOJ3yUEFedxy+sEAXPfk8sbyyO5N4OLEea5K1Xobk2Q2nNNF3zp2DO+s28V7X5Tzp+HfZ3LZvzjBuwr+eQt4fTBwHBz5n26HmTyRkNsRGJMSrMXvotyMNH574eF4BO7YPoPnwyc4Gz78k/Ny9le+726AyWZvJDMmKSzxu2xwbgYThjpzba/oP5vi8GFEvBmxD6zZneDIXGDzFBmTFJb4e4DriiYgAnd+8wjeiUzFE47R8t30Ptw1Dtb+K/bJlzwMvyvsFf3n4fpat0MwJiVY4u8BzjlsBGt/eQZHjh3A+xnHt9y4Z2PrA754y/nc8mHsk7/8XShfB5VbuxpmwtXW1TQuh0LW32+S47aXVvPgO1+6HUZSWeLvAUQEn9eDiDBgxHhu6v+bpo33HgYbFrbs2mmYwz+zX+yT5wx1Pte83G3xJkqgtqnFX+mvdjGSJFn+FGxd6s61I5G+2V3YCY+8t5FfvrLG7TCSyhJ/D3PwsH68VFrABxeu5qP0o53CJy+Au8Yx6bPfwfPfgbLouP/6OJJjXoHzueB2CAc73vet22HVc50PvosCgaYWf0VlCsxZ9OLV8OeT3Ln2B390ugv3lrhz/R7CzXeOu8kSfw9TOGYA4Ygy5+EVfLNyLl9OvByCTkIcvuPfznt5Nyx0dvbvhA3vdJysA9H5/QOVULa244svvAuevaIbatE5gbqmt4/t3tvHp66IhN29/trXAPjsk8XuxuGyytqmLsW6oMt/J0lkib+HOX3qMG498xAG5aQDUOyb2f7OSx+BR89ykvW6fztlqi1u5Gp1GRvyo7857FjZ/rma//bQ3rQRHz0Iix+IoxadUx9o6uqZ+MYVEKhK2LVc5/acTNnOlCGPvvZu3IeEwhEeeXcDNfXt3H/ZW0Lt2gVEInG2ogN+WPls3NdPhL1bVjKUPcz2LGX7ymJXY2khHHL+v4USM9LNEn8PIyJcOXM8S348m2PGD+Se1TkcH/gN5wduY7NnFCsOvIbwRc+yN/fAlge+eDWsfxP+cSP8ZpqT/OurkfoqXigbTYB02P4J/O1y+PyfrS9cub1xsWL9e/zXCytZtXWf5PTK9+GfNzvLpWugpHv7p4N1TYk/v/LztuPsK+oqOnfcun93S7KM+Jz3HRwo29hTHV9y+fvybdz2j0+5/+22b4SGHzuPrCe/xh/+tTy+IF77ETz37fbvc6x+AT59Kb5zddKQV67gd+m/48H0/2PcS+cn9Fr7I7Lsr/DK9wl/cF9Czm+Jv4cSEa6ZNQF/IESJDmWZHsTMmrs4d/UJzHrRy6K9TouNy/+JHnOd8wrHx8+HZY85L3G///jGee1X6IGsiYxyuoRWPw9PzWk9vLOqKfHnvHwtez76G3Pnfwzr/+10LTXfX9U594Pd2z8d3Hc4p9ut4kSqrWhajkScP9PyLyAYY0jrE193kmUs9TUdDuEN+p0BAkd5PuOvH8Q3DfbaUuc3sMratu8VecrXAbB5yatxnY/d0S+Qmj2tt9VXw98ug2e+Fd+5OiMSId1fwtGezxJ3jU5atW49AN5//5T8ik+7/fw2ZUMPduJBQ1h4cxGvrtrOhl3VpPl3UuEbxCsrtzOPK7kjdBFj3/Cyfe+pDK3vz7XevzPUs5dJsgV2rgLAL7m8H5nM6ZExTPcvaDr5o2ezsxbShx7EAG+d8wrIKF+4hvvS76Wy8s/wuHN/YcfZT9IwgXTpOw8xtGHnLR863QZpmc56/sima0TCsOBXMGAsHHIWVO2A4jth2jeAPFBl2YrlhDP7c+TB45i09Bct6l/32etkHnVlU8H6fzu/Ak86ve0/sJXPwpbFcObd+/Xn3OjTlyBvGIw+qqksFIAVT8Ghc8CX2bnztqW2KdlV7NhA/yX3wrJHKT3gTIZe8VTTfnWVIAIL7gCNNJWHQ+CN/vd9+y7Y9B78x4vOun8X/O8EOO0OOPbaNi8fqtlNBnCoZwP3r1sLzV4S1KZgLeNW30cBR7KtoqDtXTIGkB7YzZRIjHtJDRq+mPz7dC0G/E33sRJp72a8kX2+xEIBSIvjAcq27FoLOYMhe2CXQwtVNv2ZBH1xjN7bT64kfhE5HbgX8AIPquqdbsTRGxwwKJurT3S6dYqLi5laOIVd/gCTCsaQn+Xj9wvWIwJf6BTejzgzfh4qX3Bqzhd8zhg+9A9h6IB+/LXiFMYOziFj0Bi2bdvCGRtfpoAI4R2LQJz/gG96juONwGTu9D3Idh3IcGka7jfsHxc1Lg9963tNAf7llBbxRvqNxHPIObBnA6x7vSlZvXR9006fvsi4obOh+FyOAPZoLmXHXM/guh0A7DjkCoateYjML18nuPgv+I64GEJ18PjXneO/dj+gTteVxwuFV8CyR+Hde53tM2+G7MHOC13yRzsJMlgHaRlEAn48mXnO+u4voWCyc0w41NS6vC36m0YogC5/Enn5u7zz7kJOuPGhxnIiIRAvbFrE0J3vEa6bwduvPsX0cQUMnH6Ok6zbEw7CxncaVz1PXwR7nVbn0M2v8rfffI/+mcIpV/wC/eOxSGXrkTerP/uUKVMOdfqAF9zuFG75EIZPb1zX5U8g9dUw6QwYNrXp4PoasnZ+zKbIUMZ4Sjlz5/1o5Iz2463ZTeTJC5jj/5Bj0l/jnU3HEln3H3gmnty0T10l6QHn38uBbG7nRC2FIhHSgLrdW8gE6urqeP+vP6Vo659a7Beo2EZG/xHOSrCu/S/gbR/DwAOdYc6qzj2i9Ny2/y7e+x28/mMAKtMG0i/kxL5782oGjj8irvhbqNqJ/vFoFA+e738GuUNabq/Y4nwhpOfEdbrsyqbutG3eEfsfTwyS7OFMIuIF1gKnACXAR8CFqtru7zOFhYW6ZMmSTl2vuLiYWbNmderYnqatumzZXUO/LB8+r1BTH+b9L8q59811rC/1k53u5YaTJnL1ieO55vFlvLZ6R+NxPkIESSOHWmZ41rJNBxHoP4Efnn4Iazds4ohDDuS+N1bxYUktX/Gs5FjPp4yVneT6wB9UZnpW8u/IERwimznEs5laTSdLWvcV7/QUUBBp2aILq+CV1v/uvpDR/GzYH3j8OyfyvUfeZN6GyxginRvWGZE0POrchKzNGkZW7Q5CpBEBKvMmklm7k9zQbvzefEoHzGAo5eSWrQBgmfcwRmcHGVLV8p9kjbcf2/OmUuCtIm3vJkjLILNuFwB1kkGmOk9ch/FQn96fivzJhNKyGVLxCf6CQoKkMXDLv0kPVyPE/n9Xkz2C7JptbW7byAgKMkOkByvxhuva3Ke5naPPYGDpB5QNOZZBu5eRXrODJ0MncVbWJ/QLlrEtfQxrMw7loKmFZGbnkhasYvPWEjZu2swxrGBwqPUN/y8mXEbOgAKyg3tgzwb6bXqDEh3MKCmjZNBX2JI/gxHjDqF//Q5IS0dzRyDhAFVbP6NevYxa9QfSI3V8nj6FoUXXEHz7fxlat7HN+Ded+BvywnvIf+9XbCg4lTGlC/CFayg98U5yRk/Du3s9ma/Opdo3gLIxX2XM+scB2DB0NlUHnkWGRAgr5FFNzqq/MrCq6beS9w79FYdvf5qsXc7ff/mB5xPsN5pAbTUZQyeQmT+UYM1eIipkDxkL4QBVq/7J4LVPIxqmLGciw/2rG88XSMtj61G34skbRk7tVmordjHqk9+y1zuAitn/i6dqO8G92wl488gaOYXBQ4YhlVuJ1FezpzZMSVkFx6/8Mc+Hj+eO4EX8x4wCbvjm7Jh/x20RkaWqWtiq3IXEfyxwm6qeFl2fB6Cqd7R3jCV+R7x1UVVCEcXn9bQoW7O9ijJ/gKPHD+Ttz3cxbVQ+/bPSee+LMsr99Zx3xMgWxwRCYXweZ/3vK7YyODeDEyYO4V+rd/DO2lJqg8rKrRWcPnkI5TVhvjK0njc2R9ixYzveSJB69bIzlMOYfh6O67+boqLTWFvqp3zXdlYu+4BdNSFGHXYSBVpO+bK/syL3K9z89VkcP3EwAD95+CVq1r3LJM8WcqnlvfRjCKswNquOwVmwe9d29ngGcnL4Xd6UozncuwGCtUzwbKNU+zPVs4EMgmzXgQyUKio0F0WoJhMfIYZKBdWSgycSYpDsJUQaq31TmRL+jL3hDJZEDmKaZwNvZs6mMLgUCQU4wrOOTGnqHghoGn6ySSPET4OXccggD1dW/REvEbZEhhDAxxCpIJN6PCirdByTZSOVZPObjKs5Ir+ak0ofZX3/4zj40t/y+qsvIDXlyPblnBR5jwWR6VQefCHjpx9P2Yu3klVXykCpZJSUNf5G9ufQmUyQrRR5ncR1b+g8cgePZk7FA1RrJvWkMUrKGmOu1GzuDZ/PtuGz+fl5M6h+8CxywxX0o4YMadn1UUU2dZrGn0Jnk33QLK49uJoPFr+L7tnE8ZGl+CRMQNPIkBAf6iFsmHQVM9bewwRiv1cipB42aQEHepruL90fOpujTz6fQ2o+wuPLIv29/4t5nuaaNyr2aC4DxN9qn82RIazTUQyX3QyQKqq/vYgJB4xk2eO3csT63zeeJ4SXDGn/CfI69VEtOZRG+iEo4axBvBuZwhX1T5EmkXaPi0cIL5WXvMbufpNZ/8lHnD67qFPn6UmJ/xvA6ar6n9H1bwFHq+r1++x3FXBVdHUS8DmdMxgoi7lX72B16Zn6Sl36Sj3A6tJgjKoO2bfQjT7+tjo/W337qOoDQJcHjYvIkra+8Xojq0vP1Ffq0lfqAVaXWNwYzlkCjG62PgpouyPTGGNMt3Mj8X8ETBSRcSKSDswBEvuUhjHGmEZJ7+pR1ZCIXA/8C2c450OqujrGYV2RuDkGks/q0jP1lbr0lXqA1aVDSb+5a4wxxl02ZYMxxqQYS/zGGJNi+nTiF5HTReRzEVkvIj9yO55YROQhESkVkVXNygaKyBsisi76OaDZtnnRun0uIqe5E3VrIjJaRBaIyBoRWS0ic6PlvbEumSLyoYisiNbl59HyXlcXcJ6cF5GPReTl6HpvrcdGEVkpIstFZEm0rLfWpb+IPCsin0X/zxyb8Lqoap/8wblx/AUwHkgHVgCT3Y4rRswzgSOAVc3K7gJ+FF3+EfA/0eXJ0TplAOOidfW6XYdobMOBI6LLeThTdEzupXURIDe67AMWA8f0xrpE4/se8CTwcm/99xWNbyMweJ+y3lqXR4H/jC6nA/0TXZe+3OI/Clivql+qaj0wHzjX5Zg6pKoLgX1fhHouzj8Mop9fa1Y+X1UDqroBWI9TZ9ep6nZVXRZdrgLWACPpnXVRVW147t8X/VF6YV1EZBTwVeDBZsW9rh4d6HV1EZF+OA2+vwCoar2qVpDguvTlxD8SWkwYUhIt620KVHU7OAkVGmdE7hX1E5GxwOE4LeVeWZdo98hyoBR4Q1V7a11+A/wQaD6RTG+sBzhfvq+LyNLo9C7QO+syHtgFPBztgntQRHJIcF36cuKPa2qIXqzH109EcoHngO+qakfTbPbouqhqWFWn4zxlfpSITO1g9x5ZFxE5CyhV1Xhfm9Yj69HMV1T1COAM4DoR6eAdpT26Lmk43bv3qerhQDVO1057uqUufTnx95WpIXaKyHCA6GdptLxH109EfDhJ/wlVfT5a3Cvr0iD6K3gxcDq9ry5fAc4RkY043Z4nicjj9L56AKCq26KfpcALON0dvbEuJUBJ9LdIgGdxvggSWpe+nPj7ytQQLwGXRpcvBf7erHyOiGSIyDhgIvChC/G1IiKC02e5RlXvabapN9ZliIj0jy5nAbOBz+hldVHVeao6SlXH4vxfeEtVL6GX1QNARHJEJK9hGTgVWEUvrIuq7gC2iMikaNHJwKckui5u39FO8N3yM3FGlHwB3Op2PHHE+xSwHQjifLN/GxgEvAmsi34ObLb/rdG6fQ6c4Xb8zeI6HufXz0+A5dGfM3tpXQ4FPo7WZRXw02h5r6tLs/hm0TSqp9fVA6dffEX0Z3XD/+3eWJdobNOBJdF/Yy8CAxJdF5uywRhjUkxf7uoxxhjTBkv8xhiTYizxG2NMirHEb4wxKcYSvzHGpBhL/MYAIhKOzvTY8NNts7mKyFhpNuOqMW5L+qsXjemhatWZlsGYPs9a/MZ0IDrv+/9E5+T/UEQmRMvHiMibIvJJ9POAaHmBiLwQnb9/hYgcFz2VV0T+HJ3T//XoU8DGuMISvzGOrH26ei5otq1SVY8Cfo8zwyXR5cdU9VDgCeC30fLfAm+r6mE4c66sjpZPBP6gqlOACuDrCa2NMR2wJ3eNAUTEr6q5bZRvBE5S1S+jE8/tUNVBIlIGDFfVYLR8u6oOFpFdwChVDTQ7x1ic6ZwnRtdvAXyq+sskVM2YVqzFb0xs2s5ye/u0JdBsOYzdXzMussRvTGwXNPt8P7r8Hs4slwAXA4uiy28C10DjC1z6JStIY+JlrQ5jHFnRt2w1eE1VG4Z0ZojIYpyG0oXRshuBh0TkZpw3KF0eLZ8LPCAi38Zp2V+DM+OqMT2G9fEb04FoH3+hqpa5HYsx3cW6eowxJsVYi98YY1KMtfiNMSbFWOI3xpgUY4nfGGNSjCV+Y4xJMZb4jTEmxfx/u2bXBgi1vvkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real value: 6.119691535407124, model predicted: [[6.3715043]]\n"
     ]
    }
   ],
   "source": [
    "tp_indx = 4\n",
    "print(f\"real value: {y_test[tp_indx]}, model predicted: {model.predict(x_test[tp_indx].reshape(1,-1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-dimensional optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scipy.optimize.minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer sequential_2 is incompatible with the layer: : expected min_ndim=2, found ndim=1. Full shape received: (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-7fe990955106>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Nelder-Mead'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\prodopt\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nelder-mead'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_neldermead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'powell'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_powell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\prodopt\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_minimize_neldermead\u001b[1;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, **unknown_options)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 723\u001b[1;33m         \u001b[0mfsim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    724\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m     \u001b[0mind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfsim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\prodopt\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\prodopt\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m       \u001b[0minput_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\prodopt\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    237\u001b[0m                          \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m                          \u001b[1;34m'. Full shape received: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m                          str(tuple(shape)))\n\u001b[0m\u001b[0;32m    240\u001b[0m     \u001b[1;31m# Check dtype.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer sequential_2 is incompatible with the layer: : expected min_ndim=2, found ndim=1. Full shape received: (3,)"
     ]
    }
   ],
   "source": [
    "x0 = x_train[-1].reshape(1,-1)\n",
    "res = minimize(model, x0, method='Nelder-Mead', tol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nevergrad - A gradient-free optimization platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3_w,7)-aCMA-ES (mu_w=2.3,w_1=58%) in dimension 3 (seed=nan, Thu Jan 14 15:13:25 2021)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer sequential_2 is incompatible with the layer: : expected min_ndim=2, found ndim=1. Full shape received: (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-87fba36ca3b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mng\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNGOpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparametrization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbudget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrecommendation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\prodopt\\lib\\site-packages\\nevergrad\\optimization\\base.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, objective_function, executor, batch_mode, verbosity)\u001b[0m\n\u001b[0;32m    575\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_finished_jobs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m                     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_finished_jobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mmultiobjective\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# hack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m                         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjective_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_aggregate_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\prodopt\\lib\\site-packages\\nevergrad\\optimization\\utils.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_computed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_computed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\prodopt\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m       \u001b[0minput_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\prodopt\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    237\u001b[0m                          \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m                          \u001b[1;34m'. Full shape received: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m                          str(tuple(shape)))\n\u001b[0m\u001b[0;32m    240\u001b[0m     \u001b[1;31m# Check dtype.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer sequential_2 is incompatible with the layer: : expected min_ndim=2, found ndim=1. Full shape received: (3,)"
     ]
    }
   ],
   "source": [
    "optimizer = ng.optimizers.NGOpt(parametrization=3, budget=100)\n",
    "recommendation = optimizer.minimize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
